[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Einführung in IoT",
    "section": "",
    "text": "Inhalt\nInternet of Things ermöglicht durch die Vernetzung physischer und virtueller Objekte Infrastrukturen aufzubauen die Echtzeit Datenerfassung und Verarbeitung ermöglichen, was für die Geomatik und GIS zunehmend an Bedeutung gewinnt. Vor allem in den Bereichen Smart Cities oder Geomonitoring wird IoT eingesetzt um automatisiert Sensordaten zu erfassen, diese zu analysieren und für Entscheidungsprozesse zu nutzen. Dieser zunehmende Fokus spiegelt auch den Bedarf an Geomatiker:innen, die sich in diese Themen vertiefen und geeignete Lösungen entwickeln können.\nIn dieser Einführung gibt einen Überblick über die Grundlagen von IoT mit einem Fokus auf die Geomatik und Geoinformation und führt anwendungsbezogen mit praktischen Beispielen mit Raspberry Pi und unterschiedlichen Sensoren in das Thema ein. Der Anhang bietet eine Einführung in Raspberry Pi mit den wichtigsten Befehlen und Anleitungen für die Installation und Konfiguration. Zusätzlich bietet er eine praktische Anleitung für den Aufbau des vorkonfigurierten Image mit den erforderlichen Installationen wie Python, Python Bibliotheken, MQTT, Node-RED, InfluxDB und Grafana, deren Konfiguration und einfache Funktionstests.",
    "crumbs": [
      "Inhalt"
    ]
  },
  {
    "objectID": "index.html#aufbau",
    "href": "index.html#aufbau",
    "title": "Einführung in IoT",
    "section": "Aufbau",
    "text": "Aufbau\nDas Skript führt in Sensorik ein und zeigt typische Anwendungen zum Thema IoT, des Weiteren zeigt es auf wie Sensordaten genutzt, gespeichert, übertragen und visualisiert werden können mittels detaillierten Beispielen und Übungen.\nDie begleitenden Übungen nutzen den Einplatinenrechner Raspberry Pi mit unterschiedlichen Sensoren für die Datenerfassung, -analyse und Visualisierung. Die Programmiersprache für diesen Kurs ist Python und das genutzte Betriebssystem ist Raspberry Pi OS, eine für den Raspberry Pi angepasste Distribution von Debian (Linux).\n\nLernziele:\n\nDie Studierenden erfahren, wie IoT (Internet of Things) und Sensordaten in räumlicher Analyse eingesetzt werden können.\nDie Studierenden lernen, wie sie mit einem Einplatinenrechner Sensordaten erfassen, auswerten, kommunizieren und visualisieren können.",
    "crumbs": [
      "Inhalt"
    ]
  },
  {
    "objectID": "index.html#kursvorbereitung",
    "href": "index.html#kursvorbereitung",
    "title": "Einführung in IoT",
    "section": "Kursvorbereitung",
    "text": "Kursvorbereitung\nFür den Kurs werden Raspberry Pi 4 mit dem Breakout Garden HAT und passenden Sensoren zur Verfügung gestellt. In den Computerräumen besteht Zugang zu externen Bildschirmen, Tastatur und Mäusen, mit denen die Übungen mit dem Raspberry Pi durchgeführt werden können.\n\n\n\nRaspberry Pi Set: Raspberry Pi 4 mit Breakout Garden HAT und Sensoren\n\n\nFür den Fernzugriff auf den Raspberry Pi und entwickeln ist ein SSH-Client (SSH Windows, Putty, Tabby), sowie eine entsprechende Entwicklungsumgebung mit Python (Anaconda, Miniconda) und Visual Studio Code empfohlen.\n\nSSH-Clients: Putty, Tabby\nPython: Anaconda, Miniconda, Python",
    "crumbs": [
      "Inhalt"
    ]
  },
  {
    "objectID": "index.html#raspberry-pi-image-kontoinformationen",
    "href": "index.html#raspberry-pi-image-kontoinformationen",
    "title": "Einführung in IoT",
    "section": "Raspberry Pi Image Kontoinformationen",
    "text": "Raspberry Pi Image Kontoinformationen\nFür die Übungen wird ein Raspberry Pi Image mit vorinstallierten Paketen und Einstellungen verwendet. Die SD-Karte mit dem Image wird von der Kursleitung zur Verfügung gestellt. Das Image kann über Moodle bezogen werden.\n\nRaspberry Pi Image Konto Einstellungen\n\n\nKonto\nUser\nPasswort\nKommentar\n\n\n\n\nRaspberry Pi\niot\nigeo@fhnw\n\n\n\ninfluxdb\niot\nigeo@fhnw\norganisation: fhnw\n\n\ngrafana\nadmin\nigeo@fhnw",
    "crumbs": [
      "Inhalt"
    ]
  },
  {
    "objectID": "index.html#übungsunterlagen",
    "href": "index.html#übungsunterlagen",
    "title": "Einführung in IoT",
    "section": "Übungsunterlagen",
    "text": "Übungsunterlagen\nDie Übungsunterlagen werden auf dieser Kurswebseite Einführung in IoT zur Verfügung gestellt und werden laufend aktualisiert.",
    "crumbs": [
      "Inhalt"
    ]
  },
  {
    "objectID": "index.html#repository",
    "href": "index.html#repository",
    "title": "Einführung in IoT",
    "section": "Repository",
    "text": "Repository\nDie Inhalte von “Einführung in IoT” sind auf der Kurswebseite frei zugänglich und sind unter CC BY-NC 4.0” lizenziert. Ideen, Änderungen und Vorschläge sind willkommen und können über das GitHub Repository eingebracht werden. Die Kurswebseite wird mit Quarto erstellt.",
    "crumbs": [
      "Inhalt"
    ]
  },
  {
    "objectID": "01_IoT.html",
    "href": "01_IoT.html",
    "title": "1  Internet of Things IoT",
    "section": "",
    "text": "Ubiquitous Computing\nAus dem Bestreben der 1980er Jahre, Technologie in den Hintergrund des Alltags einzubetten, in dem entstehenden Forschungsgebiet Ubiquitous Computing definierte dies Weiser Ubiquitous Computing (Rogers, 2006) als “die physische Welt, die reichhaltig und unsichtbar mit Sensoren, Aktoren, Anzeigen und Computerelementen verwoben ist, die nahtlos in die alltäglichen Objekte unseres Lebens eingebettet und durch ein kontinuierliches Netzwerk verbunden ist” mit dem Ziel im täglichen Leben unterstützend zu sein und nicht zu überladen.\nEthnographische Studien über den Alltag zeigen, dass der Kontext des Alltags der Menschen viel subtiler, fliessender und eigenwilliger ist, als das die Theorien über den Kontext glauben machen (Salvador & Anderson, 2003). Dies erschwert eine praktische Umsetzung und Vorhersage von Bedürfnissen auf Basis von Kontextinformationen erheblich. Zusätzlich stellen sich auch ethische und soziale Fragen. Rogers (2006) plädiert für einen proaktiven Ansatz weg von proactive Computing zu proactive people und propagiert eine fachspezifische Nutzung für bestimmte Bereiche wie beispielsweise Landwirtschaft oder Umeltsanierung und weg von der Idee von pervasive Computing. Zwei Technologien sind kritisch für diese Ansätze Cloud Computing und Internet of Things.",
    "crumbs": [
      "Theorie",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Internet of Things IoT</span>"
    ]
  },
  {
    "objectID": "01_IoT.html#ubiquitous-computing",
    "href": "01_IoT.html#ubiquitous-computing",
    "title": "1  Internet of Things IoT",
    "section": "",
    "text": "Ubiquitous Computing\n\nVision der Informatik allgegenwärtige Datenverarbeitung und Nutzung von Systemen ohne Bedienungsanforderung und Hardwarebelastung für die Nutzenden. Ubiquitäre Systeme agieren quasi unsichtbar im Hintergrund von Handlungsfelder (Wiegerling, 2013).",
    "crumbs": [
      "Theorie",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Internet of Things IoT</span>"
    ]
  },
  {
    "objectID": "01_IoT.html#internet-of-things",
    "href": "01_IoT.html#internet-of-things",
    "title": "1  Internet of Things IoT",
    "section": "Internet of Things",
    "text": "Internet of Things\nEs existiert keine einheitliche Definition für Internet of Things IoT oder das Internet der Dinge. Es ist eine Bezeichnung oder Sammelbegriff für ein Netzwerk von physischen Objekten “Things”, die untereinander vernetzt sind, mit Sensoren, Software und unterschiedlichen Technologien ausgestattet sind, und somit einen direkten Datenaustausch ermöglichen. Dies reicht von Monitoringsystemen, über Wildtierbeobachtungen, Smart City Anwendungen bis in die Haushalte die mit IoT Geräten ausgestattet sind.\nDer Standardisierungsausschuss der International Telecommunication Union (ITU) definiert IoT als eine\n\n.. a global infrastructure for the information society, enabling advanced services by interconnecting (physical and virtual) Things based on existing and evolving interoperable information and communication technologies (ITU, 2005).\n\nAshton (2009) beschrieb als früher Ideengeber zu Internets der Dinge im Kontext von Supply Chain Management folgendes:\n\n.. Ideas and information are important, but things matter much more. Yet today’s information technology is so dependent on data originated by people that our computers know more about ideas than things. If we had computers that knew everything there was to know about things — using data they gathered without any help from us—we would be able to track and count everything, and greatly reduce waste, loss and cost. We would know when things needed replacing, repairing or recalling, and whether they were fresh or past their best. We need to empower computers with their own means of gathering information, so they can see, hear and smell the world for themselves, in all its random glory. RFID and sensor technology enable computers to observe, identify and understand the world—without the limitations of human-entered data. [..] The Internet of Things has the potential to change the world, just as the Internet did. Maybe even more so.\n\nDie Kernidee von IoT ist, mit Computer Informationen, ohne menschliches zu tun zu erkennen. Wenn Dinge eigenständig Daten sammeln, diese nach Art, Messung, Messzeit und Messort geordnet werden, ermöglicht dies im Bereich der Geomatik spannende neue Ansätze, Analysen und Anwendungen. IoT ist ein multidisziplinäres Gebiet mit einem breiten Spektrum an Technologien, Protokollen, Anwendungszenarien und Disziplinen und bedingt Kenntnisse der elektronischen Komponenten, Kommunikationsprotokollen, Echtzeitdatenanalysen, und der Lokalisierung von Objekten und Geräten (Granell et al., 2020).\nFür das Konzept Ding oder Thing bestehen unterschiedliche Definitionen. Charakteristisch ist, begrenzte Ressourcen (beispielsweise geringe Rechenleistung), unzuverlässige Netwerkverbindung, geringe Kosten für Hardware und Datenübertragung, keine Stromversorgung dafür Batterienbetrieb und nicht im Office-Umfeld sondern im Feld. Aus Netzwerksicht kann es als Entität mit der Möglichkeit sich mit einem Netzwerk lokal oder dem Internet zu verbinden beschrieben werden. Aus ding-zentrierter Sicht sind die mit den Dingen verbundenen Dienste zentral. Dienste, die Datenmengen, die von intelligenten Objekten durch deren Interaktion mit der Umgebung erfasst werden, verwalten.\n\n\n\nKomponenten eines smarten Objekt “Thing” (Zaheeruddin & Gupta, 2020)\n\n\nDas Internet entwickelt sich in ein Netzwerk,\n\nin welchem Objekte miteinander verbunden werden,\nInformationen aus der Umwelt gesammelt werden (Sensorik),\nmit der physischen Welt interagiert (Steuerung) werden und\nbestehende Standards für Dienste für den Transfer, Analyse, Anwendung und Kommunikation genutzt werden.\n\nDie drei wesentlichen technologischen IoT Komponenten sind folglich:\n\nHardware mit Sensoren, Aktoren und integrierter Kommunikationstechnologie\nMiddleware bedarfsorientierte Speicher- und Datenverarbeitungswerkzeuge für die Datenanalyse\nPräsentation mit zugänglichen und nutzerfreundlichen Visualisierungs- und Interpretationswerkzeuge über unterschiedliche Plattformen und Anwendungen\n\nBetrachtet man die Dimensionen von IoT fügt sich aus der Sicht der Kommunikationstechnologie das thing mit ein (ITU, 2005). Aus Sicht der Geoinformation, sind diese drei Dimensionen sehr vertraut mit Zeit, Ort und Objekt dem thing.\n\n\n\nDimensionen der IoT, eine neue Dimension aus Sicht der Kommunikationstechnologie (ITU, 2005)\n\n\nIoT Geräte haben neben der wichtigsten Eigenschaft, dass sie mit dem Netzwerk/Internet kommunizieren können, folgende typischen Eigenschaften. Sie sind oft funkbasiert und oft batteriebetrieben. Sie lassen sich daher einfach installieren, jedoch muss im Betrieb dem Batteriebetrieb der Verbrauch berücksichtigt werden und nach Anforderung (Laufzeit vs häufige Updates) priorisiert werden1.",
    "crumbs": [
      "Theorie",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Internet of Things IoT</span>"
    ]
  },
  {
    "objectID": "01_IoT.html#digital-earth-und-iot",
    "href": "01_IoT.html#digital-earth-und-iot",
    "title": "1  Internet of Things IoT",
    "section": "Digital Earth und IoT",
    "text": "Digital Earth und IoT\nDer Vizepräsident der USA AL Gore führte 1998 in seiner Rede das Konzept der digitalen Erde ein mit der Vision die realer Erde mit einer virtuellen Nachbildung zu erweitern, einem virtuellen Zwilling (Gore, 1998).\n\nI believe we need a “Digital Earth”. A multi-resolution, three-dimensional representation of the planet into which we can embed vast quantities of geo-referenced data. Gore (1998)\n\nDie Umsetzung der Vision “Digital Earth” erfordert wie auch die IoT eine entsprechende Infrastruktur, die das Auffinden, den Zugriff, die Analyse und die Verarbeitung von raumbezogenen Daten ermöglicht. Granell et al. (2020) fordern eine permanente und verstärkte Zusammenarbeit beider Bereiche. Betrachtet man die Rolle der Netzwerke und Interaktion in beiden Bereichen, kann ein Worklow von (1) der Auffindbarkeit, Erfassung und Kommunikation räumlicher Informationen, zu (2) Verständnis räumlicher Objekte und ihrer Beziehungen, dann (3) Bestimmung des raum-zeitlichen Verhaltens und der Simulationsregeln und dem (4) Handeln und Ergreifen fundierter Maßnahmen gezeichnet werden. Bei (1) kann IoT mit neuen Quellen und höheren Aufnahme- und Übertragungsfrequenzen den Workflow anreichern und (2) erfordert eine kontinuierliche vertiefte Zusammenarbeit beider Infrastrukturen. Im Bereich IoT werden räumlichen Analysen wird aufgrund der aufkommenden Edge-Fog-Cloud Paradigmen zunehmen.\n\n\n\nIoT und Digital Earth Workflow (Granell et al., 2020)\n\n\nDie Auffindbarkeit, Erfassung und Kommunikation räumlicher Informationen erfordert das Geräte und ihre Daten auffindbar und zugänglich sind mit standardisierten Methoden in globalen zentralisierten Sammlungen, oder über dezentralen oder hierarchischen Ansätzen. Viele dieser Dienste erfordern Fachkenntnisse und einfache Zugänge zu IoT Daten fehlen. Der OGC Standard Sensor Web Enablement SWE standardisiert die Erkennung und der Zugriff auf Sensoren. Bei der räumlichen Datenerfassung in IoT haben Sensor-Metadaten eine hohe Bedeutung, wobei der SensorML-Standard einer der wichtigsten ist (Granell et al., 2020).\n\nSensor Model Language SensorML-Standard\n\nDer OGC SensorML-Standard beschreibt umfassend Sensor-Metadaten und bietet eine Schnittstelle, die das Auffinden von Sensoren und Beobachtungen folglich das Erstellen von Suchindizes erleichtert. Elemente sind Betreiber, Dienste, Standort, beobachtetes Phänomen und der zeitliche Verlauf.\n\nSensor Web Enablement SWE standards suite\n\nDer OGC SWE Standard ermöglicht die Erkennung und den Zugriff auf Sensoren und zugehörige Beobachtungsdaten über Standardprotokolle und Anwendungsprogrammierschnittstellen. Anwendung in der Erdbeobachtung, beispielsweise für das Katastrophenmanagement wie Brände, Überschwemmungen oder Vulkanausbrüche. Wobei die Unterstützung der Semantik eine Schwäche des Standards ist, Semantic Sensor Network SSN und Weiterentwicklungen wie Internet of Things Ontology IoT-O oder die Sensor, Observation, Sample, and Actuator (SOSA) Ontology, eine Zusammenarbeit zwischen W3C und OGC, nutzen Ontologien um die Semantik in IoT besser abzubilden.\n\n\nSWE umfasst zwei Suchtypen das Auffinden einzelner Sensorinstanzen und Sensordienste, wobei ersteres sich auf einzelne Geräte oder Sensornetzwerke bezieht und das Zweite die Dienste, die mit dem Sensor interagieren. Die Suche kann grob in drei Gruppen unterteilt werden:\n\nthematisch: Art der Phänomene, die ein Sensor beobachtet, z. B. Temperatur, Windstärke oder Luftdruck\nräumlich: Ort, an dem der Sensor eingesetzt wird\nzeitlich: Zeitraum, in dem die Beobachtungen gemacht werden\n\nWeiterentwicklungen im Bereich der Kommunikation zwischen things Geräten brachte neue Schnittstellen und über die Zeit geringere Kosten und Stromverbrauch der Kommunikationsschnittstellen wie Bluetooth, Wi-Fi, ZigBee, 3G-5G oder LORA. Während früher einfache Datenlogger nur Daten senden konnten verfügen die Geräte heute über die Möglichkeit Daten zu Senden und zu empfangen. Dies erlaubt die Steuerung und Anpassung des Verhaltens der Geräte. Kommunikationsprotokolle die auf Maschinenkommunikation ausgerichtet sind machine-to-machine M2M wurden entwickelt, wie das Advanced Message Queuing Protokoll (AMQP), MQTT oder das streamingorientierte Protokoll STOMP. Folgende Übersicht zeigt unterschiedliche Eigenschaften von Industriestandards für IoT über die Übertragungsdistanz, Art der Informationsübertragung und typische Anwendungsbereiche.\n\n\n\nIoT Standards, Eigenschaften, Übertragungsdistanzen und Anwendungen (Links, 2019)",
    "crumbs": [
      "Theorie",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Internet of Things IoT</span>"
    ]
  },
  {
    "objectID": "01_IoT.html#iot-und-gis",
    "href": "01_IoT.html#iot-und-gis",
    "title": "1  Internet of Things IoT",
    "section": "IoT und GIS",
    "text": "IoT und GIS\nSmarte Geräte der erzeugen grosse Datenströme mit zeitlichen und räumlichen Merkmalen, für deren Analyse die Entfernung, Fläche, Volumen oder Trajektorien entscheidend für die Datenanalyse von IoT Geräten sind. Die Vielfalt der Geräte bringt neue analytische Herausforderungen mit sich, die in der Lage sein müssen räumlich-zeitliche Echtzeitdaten mit sehr heterogenen smarten Geräten verarbeiten zu können (Trilles et al., 2017). Während Werkzeuge für die Analyse von Echtzeitdaten existieren, stellt die räumliche Komponente eine Herausforderung dar. Der Raum, wie der Standort, die Ausrichtung, Form und Grösse spielen eine wesentliche Rolle in IoT, da alle Geräte räumliche Eigenschaften aufweisen und miteinander räumlich zu einander in Beziehung stehen (beispielsweise der Standort, die Grösse und Orientierung von einem Auto und einem Fahrrad auf der gleichen Fahrbahn) (Granell et al., 2020). Erst über den Raum können Sensoren in Beziehung zu einander gebracht werden.\nAnsätze zur räumlichen-zeitlichen Datenanalyse in Echtzeit haben noch keine standardisierten Prozeduren, die einfach und breit angewandt werden können (Granell et al., 2020). Zusätzlich sollten Standards Echtzeitanalysen ermöglichen ohne grossen zusätzlichen Rechenaufwand für Geräte, die eine beschränkte Speicherkapazität und Konnektivität haben und oft mit Batterie betrieben sind. Der OGC Sensor Observation Service SOS bedingt eine eher rechenintensive Verarbeitung von XML-Dokumenten und weitere Ansätze sind in Erarbeitung, die dem Rechnung tragen.\nKamilaris & Ostermann (2018) klassieren und geben eine Übersicht von IoT Anwendungen und Forschungsprojekte im Kontext der GIScience und IoT. Die Anwendungsbiete sind vielfältig, wie in folgender Abbildung illustriert. In fast allen aufgeführten Anwendungsgebieten sind Aussagen zum Standort relevant.\n\n\n\nÖkosystem der Anwendungen in mobile Computing im Zusammenspiel mit Sensoren von IoT Geräten (Kamilaris & Ostermann, 2018)\n\n\nSie führen für die verschiedenen Anwendungsgebiete die benutzten Methodenklassen der räumlichen Analyse.\nWobei sie die Analysemethoden wie folgt gruppieren:\n\nGeometric Measures: distances and proximity of points, adjacency and connectivity\nData Mining: discovering patterns from large datasets\nBasic Analytical Operations: methods such as buffering and overlay\nBasic Analytical Methods: spatial analysis of point patterns and clusters, kernels and density analysis\nNetwork Analysis: graph measures, least-cost shortest path problems and flow modeling\nSurface Analysis & Geostatistics: Analysis of surfaces and geostatistics deal with interpolation of surfaces and kriging.\n\nSie klassieren die Anwendungsgebiete und die räumlichen Analysemethoden in folgender Tabelle.\n\nIoT Forschungsgebiet und räumliche Analysemethoden (Kamilaris & Ostermann, 2018).\n\n\n\n\n\n\n\n\n\n\n\nIoT Area\nGeometric Measures\nData Mining\nBasic Analytical Operations\nBasic Analytical Methods\nNetwork Analysis\nSurface Analysis & Geostatistics\n\n\n\n\nTourism\nX\nX\n-\nX\n-\n-\n\n\nUtility Network\nX\nX\n-\n-\nX\n-\n\n\nDisaster Monitoring\nX\n-\nX\n-\n-\nX\n\n\nHealth and disease detection\nX\nX\n-\nX\n-\nX\n\n\nTransportation\nX\nX\n-\nX\nX\n-\n\n\nLogistics and assets\n-\nX\n-\n-\nX\n-\n\n\nWildlife monitoring\n-\nX\n-\nX\nX\nX\n\n\nAgriculture\nX\n-\n-\nX\nX\nX\n\n\nCrime prediction\n-\n-\n-\nX\n-\n-\n\n\nSports and gaming\nX\n-\n-\nX\n-\n-\n\n\nEnvironment\n-\n-\nX\nX\nX\nX\n\n\n\nIn einer zweiten tabellarischen Zusammenfassung führen sie IoT basierte Methoden mit Beispielen von Generalisierung von Punktmessungen auf, welche Aussagen in grösseren Massstäben ermöglichen. Diese sind nach einzelnen IoT Methoden klassiert, wobei die ersten vier Methoden gerade für Generalisierung am beliebtesten sind.\n\nIoT Methoden für die Generalisierung von Analysen (Kamilaris & Ostermann, 2018).\n\n\nIoT-Based Method\nExamples of Generalizations\n\n\n\n\nParticipatory sensing\nDetecting emergency events at city scale [1], promoting neighborhood identity and local services [2], creating a noise map of a city [3], detecting outbreaks of dengue fever [4], developing heat maps from cyclists used for better city planning [5], producing a global spatial distribution of malaria risk [6].\n\n\nVehicular networks and transportation systems\nProactively performing urban traffic monitoring [7], travel planning based on real-time traffic information [8].\n\n\nFixed IoT sensors\nUrban decision-making assistance [9], wildlife monitoring and understanding of herd behavior [10], monitoring the area levels of air pollution [11], creating air temperature and precipitation maps [12], understanding fish-school characteristics around artificial reefs [13], estimating the level variations of the sand layer of sandy beaches or dunes [14].\n\n\nSatellite imagery\nUnderstanding how invasive species respond to landscape configuration relative to native species [15], assessing how the livestock agriculture affects the physical environment [16,17], modeling forest fire risk zones [18], earthquake risk assessment [19], planning of tsunami evacuation [20], creating digital maps with information about bacteria habitats [21], delineating groundwater potential zones in hard rock terrain [22].\n\n\nGround sensor sampling\nEstimating the Grand Canyon height map [23], generating high-risk floodplain maps [24], creating soil fertility maps [25], assessing the spatial variation of groundwater quality and producing salinity hazard maps [26], assessing the heavy metal pollution in soils [27], estimating the zinc contamination concentrations around a lake [28].\n\n\nWeb-based IoT datasets\nEstimating traffic from historical traffic flows [29], optimizing routes of public transportation based on taxi rides [30], exploring and analyzing attractive areas [31], associating assault rates to measures of population and place characteristics [32].\n\n\nCombination of IoT methods\nAssessing damage in Haiti by earthquake and facilitating emergency response [33], infrastructure asset management [34].\n\n\n\n\n\n\n\nAshton, K. (2009). That „Internet of Things“ Thing. RFID journal, 22(7), 97–114.\n\n\nGore, A. (1998). The Digital Earth. Australian Surveyor, 43(2), 89–91. https://doi.org/10.1080/00050348.1998.10558728\n\n\nGranell, C., Kamilaris, A., Kotsev, A., Ostermann, F. O., & Trilles, S. (2020). Internet of Things. In H. Guo, M. F. Goodchild, & A. Annoni (Hrsg.), Manual of Digital Earth (S. 387–423). Springer. https://doi.org/10.1007/978-981-32-9915-3_11\n\n\nITU. (2005). ITU Internet Reports 2005: The Internet of Things. International Telecommunication Union.\n\n\nKamilaris, A., & Ostermann, F. O. (2018). Geospatial Analysis and the Internet of Things. ISPRS International Journal of Geo-Information, 7(7), 269. https://doi.org/10.3390/ijgi7070269\n\n\nLinks, C. (2019). IoT Standards: The End Game - Qorvo. https://www.qorvo.com/design-hub/blog/iot-standards-the-end-game.\n\n\nRogers, Y. (2006). Moving on from Weiser’s Vision of Calm Computing: Engaging UbiComp Experiences. In P. Dourish & A. Friday (Hrsg.), UbiComp 2006: Ubiquitous Computing (S. 404–421). Springer. https://doi.org/10.1007/11853565_24\n\n\nSalvador, T., & Anderson, K. (2003). Practical Considerations of Context for Context Based Systems: An Example from an Ethnographic Case Study of a Man Diagnosed with Early Onset Alzheimer’s Disease. In A. K. Dey, A. Schmidt, & J. F. McCarthy (Hrsg.), UbiComp 2003: Ubiquitous Computing (S. 243–255). Springer. https://doi.org/10.1007/978-3-540-39653-6_19\n\n\nTrilles, S., Belmonte, Ò., Schade, S., & Huerta, J. (2017). A Domain-Independent Methodology to Analyze IoT Data Streams in Real-Time. A Proof of Concept Implementation for Anomaly Detection from Environmental Data. International Journal of Digital Earth, 10(1), 103–120. https://doi.org/10.1080/17538947.2016.1209583\n\n\nWiegerling, K. (2013). Ubiquitous Computing. In A. Grunwald & M. Simonidis-Puschmann (Hrsg.), Handbuch Technikethik (S. 374–378). J.B. Metzler. https://doi.org/10.1007/978-3-476-05333-6_71\n\n\nZaheeruddin, & Gupta, H. (2020). Foundation of IoT: An Overview. In M. Alam, K. A. Shakil, & S. Khan (Hrsg.), Internet of Things (IoT): Concepts and Applications (S. 3–24). Springer International Publishing. https://doi.org/10.1007/978-3-030-37468-6_1",
    "crumbs": [
      "Theorie",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Internet of Things IoT</span>"
    ]
  },
  {
    "objectID": "01_IoT.html#footnotes",
    "href": "01_IoT.html#footnotes",
    "title": "1  Internet of Things IoT",
    "section": "",
    "text": "Der Raspberry Pi ist insofern mit dem verhältnissmässigen hohen Stromverbrauch kein typisches IoT Device↩︎",
    "crumbs": [
      "Theorie",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Internet of Things IoT</span>"
    ]
  },
  {
    "objectID": "02_Sensoren.html",
    "href": "02_Sensoren.html",
    "title": "2  Sensoren",
    "section": "",
    "text": "Sensoren in IoT\nEiner der grossen Treiber von IoT ist die zuhnemende Verfügbarkeit von low-cost Sensoren für viele unterschiedliche Anwendungen. Standard Sensoren sind beispielweise Umweltsensoren wie Temperatur, Luftfeuchtigkeit, Luftdruck, Bewegungssensoren mit Beschleunigung, und Magnetfeld, Neigung, Standort Sensoren wie GPS oder Kamera Licht, Schall, Gas, Flüssigkeit, wie auch Gesundheitssensoren wie Herzfrequenzvariabilität sowie GSR (galvanische Hautreaktion oder Hautleitfähigkeit). Sensoren sind in der Regel mit einem Mikrocontroller verbunden, der die Messwerte verarbeitet und an einen Computer oder ein anderes Gerät überträgt.\nDer Trend geht hin zu Miniaturisierung und Multi-Sensor-Geräten mit dem Vorteil, dass über mehrere Sensoren zeitgleich(!) Messungen durchgeführt werden können und so aus der Kombination von Messwerten über Sensordatenfusion (sensor fusion) neue Erkenntnisse gewonnen werden können, beispielsweise die Kombination von GPS und Beschleunigungssensor für die Bestimmung der Position und der Geschwindigkeit (Dead Reckoning, Kalman Filter).\nSensoren können in mehrere Kategorien gruppiert werden: Umweltüberwachung (natürliche und anthropogene), Biophysikalische Sensoren und Gesundheitsüberwachung, Gebäude- und Heimautomatisierung, Automobil- und Transportanwendungen, Mobile Computing und tragbare Elektronik etc.\nViele Sensoren sind in Smartphones integriert, wie z.B. Beschleunigungssensoren, Gyroskope, Magnetometer, GPS, Lichtsensoren, Näherungssensoren, Barometer, Temperatursensoren, Feuchtigkeitssensoren, Mikrofone, Kameras, etc. Ihr Einsatz ist vielfältig, von der Unterhaltung über die Navigation bis hin zur Gesundheitsüberwachung. Mit der Applikation phyphox - physical phone experiments einer digitalien Experimentierbox, entwickelt von der RWTH Aachen University, können die Sensoren von Smartphones für physikalische Experimente genutzt werden.",
    "crumbs": [
      "Theorie",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Sensoren</span>"
    ]
  },
  {
    "objectID": "02_Sensoren.html#sensoren-in-iot",
    "href": "02_Sensoren.html#sensoren-in-iot",
    "title": "2  Sensoren",
    "section": "",
    "text": "phyphox Anwendung für physikalische Experimente mit Sensoren in Mobiletelefonen, Screenshot der Anwendung mit dem Menu und einzelnen Experimenten am Beispiel von Magnetfeld, Licht und Beschleunigung.\n\n\n\nSensorentest mit phyphox\nInstalliere auf deinem Smartphone die Applikation phyphox und teste die Sensoren deines Smartphones, wie die Beschleunigung, Orientierung (Magnetfeld), Standort oder Licht. Führe ein Experiment durch und dokumentiere deine Beobachtungen. Nutze die Anwendung für Vergleiche mit anderen Sensoren während der Übungen.",
    "crumbs": [
      "Theorie",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Sensoren</span>"
    ]
  },
  {
    "objectID": "02_Sensoren.html#sensoren",
    "href": "02_Sensoren.html#sensoren",
    "title": "2  Sensoren",
    "section": "Sensoren",
    "text": "Sensoren\nSensoren sind technische Bauteile, die bestimmte physikalische oder chemische Eigenschaften messen oder eine Beschaffenheit der Umgebung qualitativ oder quantitativ erfasst. Sensoren können unterschiedlich klassiert werden, nach der Art der Erzeugung von Energie in passive und aktive Sensoren, nach dem Messprinzip oder dem Verwendungszweck.\n\nWirkprinzip von Sensoren Quelle: wikipedia\n\n\nWirkprinzip\nBeispiel\n\n\n\n\nMechanisch\nManometer, Dehnungshebel, Federwaage, Hebelwaage, Thermometer\n\n\nThermoelektrisch\nThermoelement\n\n\nResistiv\nDehnungsmessungsstreifen, Hitzdraht, Halbleiter-DMS, Pt100\n\n\nPiezoelektrisch\nBeschleunigungssensor\n\n\nKapazitiv\nDrucksensor, Regensensor, Luftfeuchtesensor\n\n\nInduktiv\nNeigungssensor, Kraftsensor, Wegaufnehmer\n\n\nOptisch\nCCD-Sensor, Fotozelle\n\n\nAkustisch\nFüllstandssensor, Doppelbogenkontrolle, Ultraschall-Durchflussmesser\n\n\nMagnetisch\nHall-Sensoren, Reed-Kontakt\n\n\n\nDie Wahl von Sensoren für IoT Projekte hängt von der Anwendung ab und der dahinterstehenden Fragestellung. Die Fragestellung führt zur Bestimmung was gemessen wird und wie das was gemessen werden soll operationalisiert wird. Die Operationalisierung definiert die Messgrössen und der Wahl von einem oder mehreren Sensoren (Sensor Fusion) in einem IoT Projekt. Bei der Wahl sind mehrere Faktoren zu berücksichtigen, wie beispielsweise:\n\nWelche Messgrösse soll gemessen werden? Welche Genauigkeit ist erforderlich? Welche Einschränkungen gibt es?\nExistiert ein Datenblatt mit den technischen Spezifikationen?\n\nWie wird der Sensor angeschlossen? Wie wird der Sensor angesteuert?\n\nGibt es eine Einschränkung bezüglich der Temperatur und anderen Faktoren wie Feuchtigkeit?\nWie genau ist die Messung und welche Messabweichungen gibt es?\nExistiert es eine Library, welche die Ansteuerung des Sensors vereinfacht? Gibt es einfache Beispiele, welche die Ansteuerung des Sensors zeigen? etc.\n\nFür die Auswahl von Sensoren sind unter anderem folgende Aspekte zu beachten:\n\nAnwendung (z.B. Umweltüberwachung, Gesundheitsüberwachung, Gebäude- und Heimautomatisierung, Automobil- und Transportanwendungen, Mobile Computing und tragbare Elektronik)\nMessgrösse (z.B. Temperatur, Luftfeuchtigkeit, Luftdruck, Bewegung, Standort, Licht, Schall, Gas etc.) und Kombination von Messgrössen (Sensor Fusion)\nMessprinzip (z.B. mechanisch, thermoelektrisch, resistiv, piezoelektrisch, kapazitiv, induktiv, optisch, akustisch, magnetisch)\nEinschränkungen (z.B. Temperatur, Abschirmung)\nMessgenauigkeit (z.B. Auflösung, Messbereich)\nBibliotheken (z.B. Programmiersprache, Dokumentation, Community, Beispiele, Aktualität)\nMontage (Schnittstelle, Löten, HAT)\nDatenschnittstelle (I2C, UART)\nPlatzbedarf\nStromversorgung (z.B. Batterie, Solarzelle, USB)\nKosten\nVerfügbarkeit (z.B. Lagerbestand, Lieferzeit)\netc.\n\nFür Prototypenentwicklung können über verschiedene Hersteller und Distributoren Sensoren bezogen werden. Die folgende Liste gibt eine Übersicht über einige Hersteller und Distributoren von Sensoren.\n\nPi-Shop ist ein Schweizer Online Händler für Raspberry Pi und Zubehör.\nDistrilec ist ein Distributor für elektronische Bauteile in der Schweiz und Europa.\nAdafruit Industries (2005, New York, USA) ist ein Hersteller von Elektronik für Maker gegründet von der MIT-Ingenieurin Limor “Ladyada” Fried.\nSparkfun Electronics (2003, Colorado, USA) ist Open Source Elektronik Hersteller und produziert und verkauft Mikrocontroller-Plattformen, Sensoren und andere Elektronik-Komponenten.\nSeeed Technology (2008, Shenzhen, China) ist eine IoT-Innovationsplattform das sich auf Hardware-Forschung, -Produktion und -Vertrieb für Edge-Computing, Netzwerkkommunikation und Smart-Sensing-Anwendungen spezialisiert hat und viele Produkte für Maker anbietet.\nPimoroni 2012 ist ein Reseller von Raspberry Pi, Adafruit, Micro:bit, Arduino, Sparkfun, etc. Produkten und stellt auch eigene Elektronikprodukte und Kits her1.\n\n\nSensoren\nSuche Dir auf den aufgelisteten Websites für elektronische Bauteile und Kits, wie dem Raspberry Pi, welche Art von Sensoren existieren.\nSuche drei bis vier interessante Sensoren aus und überlege anhand der aufgeführten Aspekte zur Sensorauswahl, was alles benötigt wird um diese zu betreiben und was die Einschränkungen sind.",
    "crumbs": [
      "Theorie",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Sensoren</span>"
    ]
  },
  {
    "objectID": "02_Sensoren.html#footnotes",
    "href": "02_Sensoren.html#footnotes",
    "title": "2  Sensoren",
    "section": "",
    "text": "Trivia: Pimoroni steht für Pirate, Monkey, Robot, Ninja.↩︎",
    "crumbs": [
      "Theorie",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Sensoren</span>"
    ]
  },
  {
    "objectID": "03_Datenuebertragung.html",
    "href": "03_Datenuebertragung.html",
    "title": "3  Datenübertragung",
    "section": "",
    "text": "Kommunikation\nZwei Kommunikationsparadigmen kommen in IoT Systemen zum Einsatz, Publish-Subscribe und Request-Response. Je nach Szenario und Anwendungsfall kommt der eine oder andere Ansatz zum Einsatz. In der Publish-Subscribe Kommunikation sind zwei Entitäten involviert, der Publisher, der die Daten publiziert und der Subscriber, der die Daten konsumiert, eine one-to-many Kommunication. Dies ist gerade in IoT Systemen von Vorteil, wo mehrere Geräte die Daten von einem Gerät konsumieren können ohne, dass zu jedem einzelnen Gerät eine Verbindung aufgebaut werden muss. Eine one-to-one Kommunikation ist hingehen eine Request-Response Kommunikation, in der Daten zwischen zwei Entitäten ausgetauscht werden, wobei hier der Empfänger (Adresse) der Nachricht oder der Daten bekannt sein muss. In der Request-Response Kommunikation ist der Server zentraler Bestandteil der Kommunikation, wohingegen in der Publish-Subscribe Kommunikation der Broker zentraler Bestandteil der Kommunikation ist (Hirmer, 2023). Bei Publish-Subscribe muss der Broker bekannt sein wohingegen die Indentität der Publisher und Subscriber nicht erforderlich ist.\nDie zentrale Komponente beim Publish-Subscribe Modells ist der Message Broker, der für das Empfangen, Zwischenspeichern und die Vermittlung der Nachrichten zu den Subscriber verantwortlich ist. Die Nachrichten oder Datenpakete werden Topics (Themen) zugeordnert die hierarchisch strukturiert sind. So können Subscriber gewisse Topics oder Untertopics subscriben, wie beispielweise den Temperaturdaten einer Wetterstation mit stationA/temperature.\nMessage Broker können Quality of Service parameter definieren, die die Zuverlässigkeit der Nachrichtenübertragung definieren, ob beispielsweise die Nachricht genau oder mindestens einmal zugestellt werden soll. Dies geht jedoch zu Lasten der Performance, was gerade bei Echtzeitkommunikation relevant ist. Einer der wesentlichen Vorteile des Publish-Subscribe Modells ist, dass Publisher und Subscriber nicht gleichzeitig online sein müssen, da der Broker die Nachrichten zwischenspeichert und diese bei der nächsten Verbindung zustellt. Dies ist ermöglicht eine asynchrone Kommunikation in Echtzeit, eine wichtige Anforderung von IoT. Dies ist vorallem bei batteriebetriebenen Geräten sinnvoll, die energiefizient arbeiten und folglich nicht kontinuierlich online sind. Eines der verbreitesten Protokolle, die Publish-Subscribe umsetzen ist MQTT. In GeoMQTT kann eine Nachricht mit einem Zeitstempel oder Interval und einer Geometrie zusätzlich dem Topic name hinzugefügt werden. Dies ermöglicht dem Subscriber zeitliche oder räumliche Filter zusätzlich zu den thematischen Topic Filter zu nutzen Herlé et al. (2019). Ein umfangreicherer offener Standard ist AMQP, seit 2010, der auch request-response Kommunikation ermöglicht1.\nEine weitere wichtige Anforderung an IoT ist die asynchrone Kommunikation in Echtzeit. Synchrone Kommunikation in Echtzeit bedingt, dass die Uhren synchron sind und beide zur gleichen Zeit kommunizieren, was in vielen Anwendungsfällen der IoT nicht wünschenswert ist.",
    "crumbs": [
      "Theorie",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Datenübertragung</span>"
    ]
  },
  {
    "objectID": "03_Datenuebertragung.html#kommunikation",
    "href": "03_Datenuebertragung.html#kommunikation",
    "title": "3  Datenübertragung",
    "section": "",
    "text": "Kommunikationsparadigmen in der IoT Request-Response versus Publish-Subscribe",
    "crumbs": [
      "Theorie",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Datenübertragung</span>"
    ]
  },
  {
    "objectID": "03_Datenuebertragung.html#mqtt---message-queuing-telemetry-transport-protocol",
    "href": "03_Datenuebertragung.html#mqtt---message-queuing-telemetry-transport-protocol",
    "title": "3  Datenübertragung",
    "section": "MQTT - Message Queuing Telemetry Transport Protocol",
    "text": "MQTT - Message Queuing Telemetry Transport Protocol\nDas MQTT Protokoll mit dem Publisher-Subscriber Ansatz ermöglich asynchrone Kommunikation von Events in Echtzeit in dem zwischen Subscriber und Publisher ein Broker-Server in der Kommunikation dazwischen steht, der die Nachrichten zwischenspeichert. MQTT ist ein Protokoll für die Kommunikation zwischen Geräten und Servern und wurde ursprünglich für eine schlanke Datenübertragung über Satellitenkommunikation entwickelt. MQTT ist ein offenes Protokoll, das seit 1999 entwickelt wird, auf TCP/IP basiert und ab der Version 3.1 geöffnet wurde.\nDer Publisher sendet publish eine Nachricht zu einem Topic (beispielsweise gebauede1/labor1/temperature) mit einem bestimmten Quality of Service (at most once, at least once, exactly once) Parameter. Der Broker speichert die Nachricht und sendet diese an alle Subscriber, die dieses Topic abonnieren subscribe. Mosquitto ist ein quelloffener Message Broker, der die MQTT implementiert. Mosquitto ist schlank und eignet sich für den Einsatz auf allen Geräten, von stromsparenden Einplatinencomputern bis hin zu kompletten Servern. Eclipse Paho ist eine quelloffene Implementierung von MQTT und bietet Bibliotheken in verschiedenen Programmiersprachen wie Python, C++ oder Java an.",
    "crumbs": [
      "Theorie",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Datenübertragung</span>"
    ]
  },
  {
    "objectID": "03_Datenuebertragung.html#cloud-edge-und-fog",
    "href": "03_Datenuebertragung.html#cloud-edge-und-fog",
    "title": "3  Datenübertragung",
    "section": "Cloud, Edge und Fog",
    "text": "Cloud, Edge und Fog\nMit zunehmender Rechenleistung auf IoT Geräten können diese vermehrt selbst Daten prozessieren, was eine Verlagerung der Analyse ermöglicht. Die Begriffe Cloud, Edge und Fog bezeichnen im wesentlichen wo in Infrastrukturen die Datenprozessierung durchgeführt wird. In Cloud Infrastrukturen erfolgt die Prozessierung zentralisiert in der Cloud und grossen Recheninfrastrukturen, wohingegen Edge-Computing eine Infrastruktur bezeichnet, in der die lokalen Geräte selbst einen Teil der Daten dezentral und möglichst lokal verarbeiten. Fog - ein von Cisco eingeführter Begriff - bezeichnet Cloud Computing im lokalen Netzwerk, beispielsweise könnte ein Transportunternehmen die Verwaltung der Datenprozessierung in der eigenen Cloud durchführen.\n\n\n\nIm Gartner Hype Cycle for Emerging Technologies 2023 erreicht der “Hype” Cloud-Out to Edge den Peak of Inflated Expectations (Gartner, 2023). Das Hype Cycle Thema “Cloud-Out to Edge” wurde im aktualisierten Hype Cycle (2024) als Hype Thema entfernt.\n\n\n\n\n\n\nCelebi, H. B., Pitarokoilis, A., & Skoglund, M. (2020). Wireless Communication for the Industrial IoT. In I. Butun (Hrsg.), Industrial IoT : Challenges, Design Principles, Applications, and Security (S. 57–94). Springer International Publishing. https://doi.org/10.1007/978-3-030-42500-5_2\n\n\nGartner. (2023). 4 Exciting New Trends in the Gartner Emerging Technologies Hype Cycle. In Gartner. https://www.gartner.com/en/articles/what-s-new-in-the-2023-gartner-hype-cycle-for-emerging-technologies.\n\n\nGartner. (2024). Gartner 2024 Hype Cycle for Emerging Technologies Highlights Developer Productivity, Total Experience, AI and Security. In Gartner. https://www.gartner.com/en/newsroom/press-releases/2024-08-21-gartner-2024-hype-cycle-for-emerging-technologies-highlights-developer-productivity-total-experience-ai-and-security.\n\n\nHerlé, S., Bill, R., & Blankenbach, J. M. (2019). A GeoEvent-driven architecture based on GeoMQTT for the Geospatial IoT (phdthesis RWTH-2019-10695). Dissertation, Rheinisch-Westfälische Technische Hochschule Aachen, 2019.\n\n\nHirmer, P. (2023). Foundations. In P. Hirmer (Hrsg.), Model-Based Approaches to the Internet of Things (S. 7–15). Springer International Publishing. https://doi.org/10.1007/978-3-031-18884-8_2\n\n\nISO. (1994). ISO/IEC 7498-1:1994. In ISO. https://www.iso.org/standard/20269.html.\n\n\nLaska, M., Herle, S., Klamma, R., & Blankenbach, J. (2018). A Scalable Architecture for Real-Time Stream Processing of Spatiotemporal IoT Stream Data—Performance Analysis on the Example of Map Matching. ISPRS International Journal of Geo-Information, 7(7), 238. https://doi.org/10.3390/ijgi7070238",
    "crumbs": [
      "Theorie",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Datenübertragung</span>"
    ]
  },
  {
    "objectID": "03_Datenuebertragung.html#footnotes",
    "href": "03_Datenuebertragung.html#footnotes",
    "title": "3  Datenübertragung",
    "section": "",
    "text": "Diese Protokolle sind nach dem Entwurfsmuster (Design Pattern) Beobachter (Observer) implementiert↩︎",
    "crumbs": [
      "Theorie",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Datenübertragung</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Literatur",
    "section": "",
    "text": "AMS OSRAM Group. (2022). Datasheet AS7262\n6-Channel Visible Spectral_ID Device with\nElectronic Shutter and Smart Interface.\nAMS OSRAM Group.\n\n\nAriza, J. Á., & Baez, H. (2022). Understanding the role of\nsingle-board computers in engineering and computer science education:\nA systematic literature review. Computer Applications\nin Engineering Education, 30(1), 304–329. https://doi.org/10.1002/cae.22439\n\n\nAshton, K. (2009). That “internet of things” thing.\nRFID Journal, 22(7), 97–114.\n\n\nCelebi, H. B., Pitarokoilis, A., & Skoglund, M. (2020). Wireless\nCommunication for the Industrial IoT. In I.\nButun (Ed.), Industrial IoT : Challenges,\nDesign Principles, Applications, and\nSecurity (pp. 57–94). Springer International\nPublishing. https://doi.org/10.1007/978-3-030-42500-5_2\n\n\nEclipse Foundation. (2021). Authentication methods. In Eclipse\nMosquitto.\nhttps://mosquitto.org/documentation/authentication-methods/.\n\n\nGartner. (2023). 4 Exciting New Trends in the Gartner\nEmerging Technologies Hype Cycle. In Gartner.\nhttps://www.gartner.com/en/articles/what-s-new-in-the-2023-gartner-hype-cycle-for-emerging-technologies.\n\n\nGartner. (2024). Gartner 2024 Hype Cycle for Emerging\nTechnologies Highlights Developer Productivity, Total\nExperience, AI and Security. In\nGartner.\nhttps://www.gartner.com/en/newsroom/press-releases/2024-08-21-gartner-2024-hype-cycle-for-emerging-technologies-highlights-developer-productivity-total-experience-ai-and-security.\n\n\nGas sensor BME688. (2022). In Bosch Sensortec.\nhttps://www.bosch-sensortec.com/products/environmental-sensors/gas-sensors/bme688/.\n\n\nGore, A. (1998). The Digital Earth. Australian\nSurveyor, 43(2), 89–91. https://doi.org/10.1080/00050348.1998.10558728\n\n\nGranell, C., Kamilaris, A., Kotsev, A., Ostermann, F. O., & Trilles,\nS. (2020). Internet of Things. In H. Guo, M. F. Goodchild,\n& A. Annoni (Eds.), Manual of Digital Earth\n(pp. 387–423). Springer. https://doi.org/10.1007/978-981-32-9915-3_11\n\n\nGrimm, D. (2023). 2030 Geodätische Messtechnik GMT I.\n\n\nHirmer, P. (2023). Foundations. In P. Hirmer (Ed.),\nModel-Based Approaches to the Internet of\nThings (pp. 7–15). Springer International Publishing.\nhttps://doi.org/10.1007/978-3-031-18884-8_2\n\n\ninfluxdata. (2023). Get started with InfluxDB\n InfluxDB OSS v2\nDocumentation.\nhttps://docs.influxdata.com/influxdb/v2/get-started/.\n\n\nInvenSense, T. (2021). ICM-20948 World’s Lowest\nPower 9-Axis MEMS MotionTracking™\nDevice.\n\n\nISO. (1994). ISO/IEC 7498-1:1994. In\nISO. https://www.iso.org/standard/20269.html.\n\n\nITU. (2005). ITU Internet Reports 2005: The\nInternet of Things. International\nTelecommunication Union.\n\n\nJensen, K. (2020). White Paper\nChip-scale spectral sensing: Understanding the new uses for\nultra-precise light-source measurement (p. 10) [White {{Paper}}].\nAMS.\n\n\nKamilaris, A., & Ostermann, F. O. (2018). Geospatial\nAnalysis and the Internet of\nThings. ISPRS International Journal of\nGeo-Information, 7(7), 269. https://doi.org/10.3390/ijgi7070269\n\n\nLaska, M., Herle, S., Klamma, R., & Blankenbach, J. (2018). A\nScalable Architecture for Real-Time Stream\nProcessing of Spatiotemporal IoT Stream\nData—Performance Analysis on the\nExample of Map Matching. ISPRS\nInternational Journal of Geo-Information, 7(7), 238. https://doi.org/10.3390/ijgi7070238\n\n\nLeica Geosystems. (2022). Leica\nTS60/MS60/TM60\nGebrauchsanweisung.\n\n\nLinks, C. (2019). IoT Standards: The End\nGame - Qorvo.\nhttps://www.qorvo.com/design-hub/blog/iot-standards-the-end-game.\n\n\nmaxim integrated. (2020). MAX30101 High-Sensitivity Pulse\nOximeter and Heart-Rate Sensor for Wearable\nHealth.\n\n\nMelexis. (2019). MLX90640 32x24 IR array\nDatasheet.\n\n\nRaspberry Pi Ltd. (2024a). Raspberry Pi Connect Beta -\nAccess your Raspberry Pi from anywhere. In\nRaspberry Pi. https://www.raspberrypi.com/software/connect/.\n\n\nRaspberry Pi Ltd. (2024b). Raspberry Pi Documentation\nconfig.txt. In Raspberry Pi.\nhttps://www.raspberrypi.com/documentation/computers/config_txt.html.\n\n\nRogers, Y. (2006). Moving on from Weiser’s\nVision of Calm Computing: Engaging\nUbiComp Experiences. In P. Dourish & A. Friday (Eds.),\nUbiComp 2006: Ubiquitous Computing\n(pp. 404–421). Springer. https://doi.org/10.1007/11853565_24\n\n\nSalvador, T., & Anderson, K. (2003). Practical\nConsiderations of Context for Context\nBased Systems: An Example from an Ethnographic\nCase Study of a Man Diagnosed with Early Onset\nAlzheimer’s Disease. In A. K. Dey, A. Schmidt, &\nJ. F. McCarthy (Eds.), UbiComp 2003: Ubiquitous\nComputing (pp. 243–255). Springer. https://doi.org/10.1007/978-3-540-39653-6_19\n\n\nSliney, D. H. (2016). What is light? The visible spectrum\nand beyond. Eye, 30(2), 222–229. https://doi.org/10.1038/eye.2015.252\n\n\nSTMicroelectronics. (2021). VL53L5CX -\nDatasheet - Time-of-Flight 8x8\nmultizone ranging sensor with wide field of view.\n\n\nSTMicroelectronics. (2023). Description of the fields of view of\nSTMicroelectronics’ Time-of-Flight sensors.\n\n\nTrilles, S., Belmonte, Ò., Schade, S., & Huerta, J. (2017). A\ndomain-independent methodology to analyze IoT data streams\nin real-time. A proof of concept implementation for anomaly\ndetection from environmental data. International Journal of Digital\nEarth, 10(1), 103–120. https://doi.org/10.1080/17538947.2016.1209583\n\n\nUpton, E. (2022). Supply chain update - it’s good news! In Raspberry\nPi.\n\n\nWiegerling, K. (2013). Ubiquitous Computing. In A. Grunwald\n& M. Simonidis-Puschmann (Eds.), Handbuch\nTechnikethik (pp. 374–378). J.B. Metzler. https://doi.org/10.1007/978-3-476-05333-6_71\n\n\nZaheeruddin, & Gupta, H. (2020). Foundation of IoT:\nAn Overview. In M. Alam, K. A. Shakil, & S. Khan\n(Eds.), Internet of Things (IoT):\nConcepts and Applications (pp. 3–24).\nSpringer International Publishing. https://doi.org/10.1007/978-3-030-37468-6_1\n\n\nZamorano, J., García, C., Tapia, C., Miguel, A. S. de, Pascual, S.,\n& Gallego, J. (2016). STARS4ALL Night Sky Brightness\nPhotometer. International Journal of Sustainable\nLighting, 18, 49–54. https://doi.org/10.26607/ijsl.v18i0.21",
    "crumbs": [
      "Theorie",
      "Literatur"
    ]
  },
  {
    "objectID": "E01_Luftqualitaet.html",
    "href": "E01_Luftqualitaet.html",
    "title": "4  Luftqualitätmessung",
    "section": "",
    "text": "Einführung\nZiel dieser ersten Übung ist es den BME688 Sensor kennen zu lernen und die Sensordaten auszulesen. Der BME688 ist ein 4-in-1 Sensor für Temperatur, Luftdruck, Luftfeuchtigkeit und Gas Scanner VOC. Der Sensor verfügt über eine I2C Schnittstelle, die mit der Python Library bme680-python angesteuert und die Sensordaten ausgelesen werden können.\nUnterlagen:  E01_Luftqualitaet.zip\nVorbereitung",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Luftqualitätmessung</span>"
    ]
  },
  {
    "objectID": "E01_Luftqualitaet.html#einführung",
    "href": "E01_Luftqualitaet.html#einführung",
    "title": "4  Luftqualitätmessung",
    "section": "",
    "text": "Lest das Kapitel im Anhang zu Raspberry Pi\n\nKonzentriere Dich auf die wichtigsten Details zur Inbetriebnahme des Raspberry Pi\n\nLest die Dokumentation zum BME688 Sensor „Gas Sensor BME688“ (2022)\n\nKonzentriere Dich auf die Beschreibung der Schnittstelle und technische Spezifikation auf dem Datenblatt\n\n\n\n\n\n\nUnterlagen\n\n\n\n\n\nProdukt\nBME688 4-in-1 Air Quality Breakout\n\n\nDatenblatt\nBosch Datasheet BME 688\n\n\nGitHub\nbme680-python Library mit Beispielen\n\n\nTutorial\nGetting started with BME680 Breakout",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Luftqualitätmessung</span>"
    ]
  },
  {
    "objectID": "E01_Luftqualitaet.html#bme688",
    "href": "E01_Luftqualitaet.html#bme688",
    "title": "4  Luftqualitätmessung",
    "section": "BME688",
    "text": "BME688\nBME688 - Bosch Sensor für Temperatur, Luftdruck, Luftfeuchtigkeit, Gas Scanner VOC (Abb. 4.1)\n\nTemperatur +/-0.5°C (-40° .. -85°)\nLuftdruck +/-0.12hPa (300…1100hPa)\nLuftfeuchtigkeit +/-3% (0 …100%)\nGas Scanner VOC, VSCs (AI)\nPython, C Library\nRaspberry Pi Pins 1,3,5,7,9\n\n\n\n\n\n\n\nAbb. 4.1: BME688 Bosch Sensor für Luftqualitätsmessung mit Referenzbild für den Grössenvergleich",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Luftqualitätmessung</span>"
    ]
  },
  {
    "objectID": "E01_Luftqualitaet.html#übungsaufbau",
    "href": "E01_Luftqualitaet.html#übungsaufbau",
    "title": "4  Luftqualitätmessung",
    "section": "Übungsaufbau",
    "text": "Übungsaufbau\n\nSchliesse den Raspberry Pi an Monitor, Keyboard und Maus an oder verbinde Dich mit diesem über SSH (und SFTP).\nErstelle auf dem Raspberry Pi im Documents Ordner einen neuen Ordner BME688, in welchem Du Änderungen und neue Dateien für diese Übung speichern kannst.\nSchliesse den Sensor BME688 an den Raspberry Pi über die Breakout Garden I2C Schnittstelle an.\n\n\nSensor Ausrichtung beachten\nBeim Anschliessen der Sensoren in die Schnittstellen des Breakout Garden unbedingt die korrekte Ausrichtung beachten! Die Beschriftung der Anschlüsse auf dem Sensor und dem Breakout Garden müssen übereinstimmen!\n\n\n\nSensor links korrekt angeschlossen, rechts falsch ausgerichtet angeschlossen.\n\n\n\n\nKontrolle der Hardware\nKontrolliere mit dem Befehl i2cdetect -y 1 ob der Raspberry Pi mit dem Sensor verbunden ist und der Raspberry Pi Zugriff auf den Sensor hat. Erscheint eine Zahl, dann hat der Raspberry Pi den Sensor auf dem I2C Bus erkannt. Falls Du mehr über das Program und den Befehl wissen möchtest, kannst Du mit dem Befehl man i2cdetect das Manual man aufrufen.\ni2cdetect -y 1\n     0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f\n00:                         -- -- -- -- -- -- -- -- \n10: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n20: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n30: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n40: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n50: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n60: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n70: -- -- -- -- -- -- 76 --  \ni2cdetect installieren, falls das Programm nicht existiert:\nsudo apt-get update \nsudo apt install python3-smbus\nsudo apt install i2c-tools\nHinweis: Damit der Befehl i2cdetect funktioniert, muss der I2C Bus aktiviert sein. Dies kann mit dem Befehl sudo raspi-config im Menü Interfacing Options und I2C aktiviert werden.\n\n\nKontrolle der Installation\nAktiviere die virtuelle Python Environment (hier unter ~/.env) und teste ob die für die Übung erforderlichen Python Libraries installiert sind. Aktiviere über folgenden Befehl die virtuelle Umgebung, welche für diese Übungen im Homeordner ~/.env erstellt wurde1. Die aktivierte Umgebung wird durch die Anzeige des Umgebungsname in der Kommandozeile angezeigt, hier mit (.env).\nsource ~/.env/bin/activate\nTeste ob die für die Übung erforderlichen Python Libraries installiert sind. Ein einfacher Test zur Kontrolle, ob ein Modul installiert ist, ist über das Import Statement des Moduls über die Python Konsole im Terminal. Falls kein Fehler auftritt, ist das Modul in der virtuellen Environment installiert.\npython -c \"import math\"\n10\npython -c \"import numpy\"\n2Traceback (most recent call last):\n  File \"&lt;string&gt;\", line 1, in &lt;module&gt;\nImportError: No module named numpy\n\n1\n\nmath Modul existiert\n\n2\n\nnumpy Modul existiert nicht\n\n\nInstalliere das Modul mit folgendem Befehl, falls es nicht installiert ist.\npip install bme680\n\n\nKopiere (Clone) die Library mit den Beispielen auf den Raspberry Pi\nWechsle in den Ordner Documents und kopiere mit folgenden Befehlen die Library auf Deinen Raspberry Pi.\ncd Documents\ngit clone https://github.com/pimoroni/bme680-python \ncd bme680-python/examples",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Luftqualitätmessung</span>"
    ]
  },
  {
    "objectID": "E01_Luftqualitaet.html#aufgabe-1-sensormessungen-ausführen",
    "href": "E01_Luftqualitaet.html#aufgabe-1-sensormessungen-ausführen",
    "title": "4  Luftqualitätmessung",
    "section": "Aufgabe 1: Sensormessungen ausführen",
    "text": "Aufgabe 1: Sensormessungen ausführen\nTeste das Beispiel read-all.py im Ordner examples. Dieses Beispiel gibt die Temperatur, Luftdruck und Luftfeuchtigkeit des Sensors BME 688 aus.\npython read-all.py\nMit Ctrl+c kann das Script wieder gestopppt werden. Die Ausgabe sollte in etwa so aussehen (gekürzt):\n# Output Beispiel\nread-all.py - Displays temperature, pressure, humidity, and gas.\nPress Ctrl+C to exit!\n\nCalibration data:\npar_gh1: -10\n…\n\nInitial reading:\ngas_index: 0\ngas_resistance: 1338124.79581836\nheat_stable: False\nhumidity: 44.397\nmeas_index: 0\npressure: 990.82\nstatus: 32\ntemperature: 28.89\n\nPolling:\n28.89 C,990.82 hPa,44.39 %RH\n28.91 C,990.82 hPa,44.37 %RH,5684.846331497602 Ohms\n28.94 C,990.80 hPa,44.31 %RH,5684.846331497602 Ohms\n28.97 C,990.81 hPa,44.24 %RH,5684.846331497602 Ohms\n29.00 C,990.81 hPa,44.19 %RH,5684.846331497602 Ohms\n29.03 C,990.82 hPa,44.12 %RH,5684.846331497602 Ohms\nFolgendes Code Snippet zeigt eine gekürtzte Version des read-all.py Python Beispiels, der die Temperatur, Luftdruck und Luftfeuchtigkeit mit der BME680 Library ausgibt.\n#!/usr/bin/env python\nimport bme680\ntry:                                               \n1    sensor = bme680.BME680(bme680.I2C_ADDR_PRIMARY)\nexcept (RuntimeError, IOError):\n    sensor = bme680.BME680(bme680.I2C_ADDR_SECONDARY)\n\n# Oversampling Einstellungen\n2sensor.set_humidity_oversample(bme680.OS_2X)\nsensor.set_pressure_oversample(bme680.OS_4X)\nsensor.set_temperature_oversample(bme680.OS_8X)\nsensor.set_filter(bme680.FILTER_SIZE_3)\n\nprint('Sensordaten:')\ntry:\n    while True:\n3        if sensor.get_sensor_data():\n            output = '{0:.2f} C,{1:.2f} hPa,{2:.3f} %RH'.format(\n                sensor.data.temperature,\n                sensor.data.pressure,\n                sensor.data.humidity)\n            print(output)\nexcept KeyboardInterrupt:\n    pass\n\n1\n\nTesten der beiden möglichen I2C Adressen\n\n2\n\nOversampling Einstellungen können Messungen durch Mitteln verbessern und das Rauschen und Drifts reduzieren\n\n3\n\nSensordaten auslesen\n\n\n\nÜbung 4.1 BME 688\nStudiert die Python Skripte und online Tutorial zum Sensor\n\nWie wird auf den Sensor zugegriffen?\nWie reagiert der Feuchtigkeitssensor auf Änderungen?\nWie hoch sind die Werte für den Luftdruck, was sind Vergleichswerte?\nWie könnt Ihr einfach Sensorwerte in eine Datei schreiben?",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Luftqualitätmessung</span>"
    ]
  },
  {
    "objectID": "E01_Luftqualitaet.html#aufgabe-2-berechnung-der-atmosphärenkorrektur-für-distanzmessungen-optional",
    "href": "E01_Luftqualitaet.html#aufgabe-2-berechnung-der-atmosphärenkorrektur-für-distanzmessungen-optional",
    "title": "4  Luftqualitätmessung",
    "section": "Aufgabe 2: Berechnung der Atmosphärenkorrektur für Distanzmessungen (optional)",
    "text": "Aufgabe 2: Berechnung der Atmosphärenkorrektur für Distanzmessungen (optional)\nGeödätische Distanzmessverfahren wie bei der Tachymetrie (Totalstationen) und Laserscanning benötigen eine Korrektur der Messwerte, um die Distanz zwischen zwei Punkten auf der Erde zu berechnen. Über eine Massstabskorrektur (ppm [mm/km]) können distanzproportionale Reduzierungen berücksichtigt werden, die Projektionsverzerrung, Reduktion auf Meereshöhe und die Atmophärenkorrektur berücksichtigen. Die Luftfeichtigkeit beeinflusst Distanzmessungen in feuchtem und heissen Klima. Diese muss den zur Messzeit geltenden atmosphärischen Bedingungen angepasst werden.\nDie Korrektur wird als Atmosphärenkorrektur bezeichnet und ist abhängig von der Temperatur, dem Luftdruck und der Luftfeuchtigkeit. Die Korrektur wird in ppm (parts per million [mm/km]) angegeben und kann mit folgender Gleichung 4.1 berechnet werden (Grimm, 2023; Leica Geosystems, 2022, S. 87) und gilt für die Distanzmessung mit sichtbaren roten Laser\n\\[\n\\Delta D_1 = 286.338 - \\begin{bmatrix}\\frac{0.29535 \\cdot p}{(1+\\alpha \\cdot t)}-\\frac{4.126 \\cdot 10^{-4} \\cdot h}{(1+\\alpha \\cdot t)} \\cdot 10^x\\end{bmatrix}\n\\tag{4.1}\\]\n\\[\\begin{aligned}\n& \\Delta D_1 && \\text{Atmosphärische Korrektur} && [ppm]\\\\\n& p && \\text{Luftdruck} && [mbar]\\\\\n& t && \\text{Lufttemperatur} && [°C]\\\\\n& h && \\text{relative Luftfeuchte} && [\\%]\\\\\n& \\alpha && = \\frac{1}{273.15} \\\\\n& x && = (7.5 \\cdot \\frac{t}{237.3 +t}) + 0.7857 \\\\\n\\end{aligned}\n\\]\nFolgende Funktion in Python berechnet die Atmosphärenkorrektur für Geodätische Distanzmessverfahren basierend auf der Gleichung 4.1\nimport math\ndef calculate_atmospheric_correction(temperature, air_pressure, humidity):\n    # Constants\n    ALPHA = 1 / 273.15\n    X = (7.5 * temperature / (237.3 + temperature)) + 0.7857\n\n    # Interim results\n    denominator = 1 + ALPHA * temperature\n\n    formula0 = 286.338\n    formula1 = 0.29535 * air_pressure / denominator\n    formula2 = 4.126 * 10 ** (-4) * humidity / denominator\n    formula3 = 10 ** X\n\n    # ppm-calculation\n    correction_ppm = round(formula0 - (formula1 - formula2 * formula3), 2)\n\n    # Return important values as a dictionary\n    result = {\n        \"temperature\": temperature,\n        \"air_pressure\": air_pressure,\n        \"humidity\": humidity,\n        \"correction_ppm\": correction_ppm\n    }\n    return result\nFür Distanzmessungen höchster Genauigkeit sollte die atmosphärische Korrektur auf \\(1 ppm\\) genau bestimmt werden, folglich sollten die Messwerte mindestens folgenden Genauigkeit aufweisen: die Temperatur auf \\(1°C\\), der Luftdruck auf \\(3 mbar\\) (\\(1 Millibar= 1 hPa\\)) und die Luftfeuchtigkeit auf \\(20 %\\) genau bestimmt werden (Leica Geosystems, 2022, S. 87).\n\nÜbung 4.2 Atmosphärenkorrektur\nNutzt die Funktion calculate_atmospheric_correction um eine atmosphärische Korrektur mit den momentan gemessenen amtmosphärischen Bedingungen zu berechnen.\n\nWie hoch ist die Korrektur mit den Werten des BME688 Sensors?\nWie hoch ist dieselbe Korrektur bei doppelter Luftfeuchtigkeit?\nWie hoch ist die Korrektur bei 20°C, 1000hPa und 50% sowie 100% Luftfeuchtigkeit?\nErfüllt der BME688 Sensor die Anforderungen für Distanzmessungen höchster Genauigkeit?\n\n\n\n\n\n\nGas Sensor BME688. (2022). In Bosch Sensortec. https://www.bosch-sensortec.com/products/environmental-sensors/gas-sensors/bme688/.\n\n\nGrimm, D. (2023). 2030 Geodätische Messtechnik GMT I.\n\n\nLeica Geosystems. (2022). Leica TS60/MS60/TM60 Gebrauchsanweisung.",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Luftqualitätmessung</span>"
    ]
  },
  {
    "objectID": "E01_Luftqualitaet.html#footnotes",
    "href": "E01_Luftqualitaet.html#footnotes",
    "title": "4  Luftqualitätmessung",
    "section": "",
    "text": "In dieser Übung wird die Python Virtual Environment .env im Homeordner ~/ erstellt und aktiviert. Diese kann auch an einem Ort erstellt werden, beispielweise projektbasiert. Erstellen einer Virtual Environment: python -m venv ~/Development/Projekt1/env↩︎",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Luftqualitätmessung</span>"
    ]
  },
  {
    "objectID": "E02_Spektralmessung.html",
    "href": "E02_Spektralmessung.html",
    "title": "5  Spektralmessung",
    "section": "",
    "text": "Einführung\nZiel dieser Übung ist es den AS7262 Spektralsensor kennen zu lernen und die Sensordaten auszulesen. Der AS7262 ist ein Spektralsensor, der über eine I2C Schnittstelle mit dem Raspberry Pi verbunden wird und einer Python Library angesteuert werden kann.\nUnterlagen:  E02_Spektralmessung.zip\nVorbereitung",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Spektralmessung</span>"
    ]
  },
  {
    "objectID": "E02_Spektralmessung.html#einführung",
    "href": "E02_Spektralmessung.html#einführung",
    "title": "5  Spektralmessung",
    "section": "",
    "text": "Schaut das Video von AMS zum AS7262 Spektralsensor (bis Minute 2:20)\nLest das White Paper von Jensen (2020) über Spektralsensoren\n\nKonzentriere Dich da auf die Beschreibung der Multi-channel spectral sensors und in welchen Gebieten diese Sensoren eingesetzt werden.\n\nStudiert das Datenblatt zum AS7262 Spektralsensor AMS OSRAM Group (2022)\n\nIn welchen Temperaturbereichen kann der Sensor eingesetzt werden?\n\n\n\n\n\n\nUnterlagen\n\n\n\n\n\nProdukt\nAS7262 Breakout\n\n\nDatenblatt\nAS7262\n\n\nGitHub\nas7262-python\n\n\nVideo\nams Spectral ID iSPI Eval Kit",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Spektralmessung</span>"
    ]
  },
  {
    "objectID": "E02_Spektralmessung.html#spektrometer",
    "href": "E02_Spektralmessung.html#spektrometer",
    "title": "5  Spektralmessung",
    "section": "Spektrometer",
    "text": "Spektrometer\nSpektrometer, sind Sensoren, die das Licht auf einzelne Bänder der Wellenlänge (in Nanometer nm) messen. Für das menschliche Auge wird das sichtbare Spektrum zwischen 360nm bis 830nm angegeben, wobei sich der Bereich unter optimalen Bedingungen in UV und NIR erstrecken kann (Sliney, 2016).\nAuf kleinen Chip verbaute Spektralsensoren ermöglichen zahlreiche neue Anwendungen, die früher mit grossen Spektroskopen durchgeführt wurden. Die Spektralsensorsysteme finden Anwendung wie Farbbestimmung, Authentifizierung und Spektralanalyse von Substanzen, Materialien, Lebensmitteln und Flüssigkeiten und werden in den Bereichen von Konsumgütern, Industrie und Medizin eingesetzt.\nEin Multispektralsensor liefert die Antwort auf die Frage, ob eine orangefarbene Probe eine Mischung aus Rot und Gelb oder ein reines Orange ist. Multispektralsensoren teilen das gewählte Spektrum in Spektralkanäle auf (siehe Abb. 5.1) und sind so angeordnet, dass die Spektralkanäle kontinuierlich gut abgedeckt sind. Die Messung erfolgt im sichtbaren Bereich radiometrisch (Jensen, 2020). Das heißt, der Sensor misst die spektrale Leistungsverteilung der Messung.",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Spektralmessung</span>"
    ]
  },
  {
    "objectID": "E02_Spektralmessung.html#as7262-multispektralsensor",
    "href": "E02_Spektralmessung.html#as7262-multispektralsensor",
    "title": "5  Spektralmessung",
    "section": "AS7262 Multispektralsensor",
    "text": "AS7262 Multispektralsensor\nDer AS7262 ist ein sehr kompakter Multispektralsensor, der über 6 Spektralkanäle im sichtbaren Bereich misst. Der Sensor eignet sich für spektroskopische Messungen wie Farbmessung, Absorption, Bestrahlungsstärke, Reflexion und Transmission. Der Sensor ist auf einem Breakout Board verbaut und kann über die I2C Schnittstelle mit dem Raspberry Pi verbunden werden, zusätzlich sind zwei LEDs verbaut, die den Messbereich für Messungen beleuchten können.\nAS7262 - 6-Kanal Spektral Sensor (Abb. 5.1)\n\n6 Spektralkanäle (450, 500, 550, 570, 600, 650nm)\n2 on-board Beleuchtungs-LEDs\nI2C interface (address: 0x49)\nPython Library\nwerkseitig kalibriert\n\n\n\n\n\n\n\nAbb. 5.1: links: Spektrale Sensitivität des AS7262, oben: AS7262 Breakout von Pimoroni, unten: AS7262 Photodioden Array",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Spektralmessung</span>"
    ]
  },
  {
    "objectID": "E02_Spektralmessung.html#übungsaufbau",
    "href": "E02_Spektralmessung.html#übungsaufbau",
    "title": "5  Spektralmessung",
    "section": "Übungsaufbau",
    "text": "Übungsaufbau\n\nSchliesse den Raspberry Pi an Monitor, Keyboard und Maus an oder verbinde Dich mit diesem über SSH (und SFTP).\nErstelle auf dem Raspberry Pi im Documents Ordner einen neuen Ordner AS7262, in welchem Du Änderungen und neue Dateien für diese Übung speichern kannst.\nSchliesse den Sensor AS7262 an den Raspberry Pi über die Breakout Garden I2C Schnittstelle korrekt an (siehe E01 Luftqualität), so dass die Beschriftung der Anschlüsse am Sensor und bei der Schnittstelle übereinstimmen.\nKontrolliere mit dem Befehl i2cdetect -y 1 ob der Raspberry Pi mit dem Sensor verbunden ist. Der Sensor sollte auf der Adresse 0x49 erkannt werden.\nAktiviere die virtuelle Environment von Python mit source ~/.env/bin/activate und kontrolliere, ob die Library as7262 installiert ist mit python -c \"import as7262\". Bei einer Fehlermeldung muss die Library in der aktivierten virtuellen Environment mit pip install as7262 installiert werden.\n\nWechsle in den Ordner Documents und kopiere mit folgenden Befehlen die Library auf Deinen Raspberry Pi.\ncd Documents\ngit clone https://github.com/pimoroni/as7262-python\ncd as7262-python/examples",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Spektralmessung</span>"
    ]
  },
  {
    "objectID": "E02_Spektralmessung.html#aufgabe-1-spektralmessungen-durchführen",
    "href": "E02_Spektralmessung.html#aufgabe-1-spektralmessungen-durchführen",
    "title": "5  Spektralmessung",
    "section": "Aufgabe 1: Spektralmessungen durchführen",
    "text": "Aufgabe 1: Spektralmessungen durchführen\nTeste das Beispiel spectrum.py im Ordner examples. Dieses Beispiel gibt die Messungen der einzelnen Spektralkänale aus.\nStartet das Script mit python spectrum.py1. Mit Ctrl+c kann das Script wieder gestopppt werden. Die Ausgabe sollte in etwa so aussehen (gekürzt):\npython spectrum.py\nOrange: 30.22943878173828\nRed:    14.262250900268555\nOrange: 22.67207908630371\nYellow: 14.271308898925781\nGreen:  13.56598949432373\nBlue:   6.527451515197754\nViolet: 7.2663960456848145\nFolgendes Code Snippet zeigt eine gekürzte Version des spectrum.py Python Beispiels für die Ausgabe der Spektralmessungen der 6 Kanäle:\n#!/usr/bin/env python\nfrom as7262 import AS7262\nas7262 = AS7262()\n1as7262.set_gain(64)\nas7262.set_integration_time(17.857)\nas7262.set_measurement_mode(2)\nas7262.set_illumination_led(1)\n\ntry:\n    while True:\n2        values = as7262.get_calibrated_values()\n        print(\"\"\"\nRed:    {}\nOrange: {}\nYellow: {}\nGreen:  {}\nBlue:   {}\nViolet: {}\"\"\".format(*values))\n\nexcept KeyboardInterrupt:\n    as7262.set_measurement_mode(3)\n    as7262.set_illumination_led(0)\n\n1\n\nSensor konfigurieren, setzen des Gains, der Integrationszeit, des Messmodus und der Beleuchtungs LED\n\n2\n\nKalibrierte Messwerte auslesen und darstellen\n\n\n\nÜbung 5.1 AS7262 Messwerte interpretieren\nFührt einige Messungen mit unterschiedlichen Lichtquellen und Materialien durch und notiert Euch die Messwerte. Was beobachtet Ihr?\n\nMessung mit Tageslicht\nMessung mit LED-Taschenlampe des Smartphones\nMessung mit LED-Taschenlampe und Farbfilter (Mäppli)\nMessung mit weissem Papier",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Spektralmessung</span>"
    ]
  },
  {
    "objectID": "E02_Spektralmessung.html#aufgabe-2-spektralmessungen-mit-visualisierung-in-der-konsole",
    "href": "E02_Spektralmessung.html#aufgabe-2-spektralmessungen-mit-visualisierung-in-der-konsole",
    "title": "5  Spektralmessung",
    "section": "Aufgabe 2: Spektralmessungen mit Visualisierung in der Konsole",
    "text": "Aufgabe 2: Spektralmessungen mit Visualisierung in der Konsole\nDas Beispiel bargraph.py zeigt die Messwerte der Spektralkanäle in einem Balkendiagramm an. Die Messwerte werden in der Konsole ausgegeben, nach einem Weissabgleich. Der Weissabgleich wird benötigt damit der Sensoren die Messwerte korrekt in Referenz zu Weiss interpretiert.\nFür diese Aufgabe benötigt Ihr ein weisse Blatt Papier, mit welchem der Sensor den Weissabgleich durchführt. Dafür hält ihr dieses circa 5cm vor den Sensor, drückt eine Taste und der Sensor führt den Weissabgleich durch. Danach könnt Ihr das Papier wieder wegnehmen und die Messungen durchführen.\n\nÜbung 5.2 Verteilung der Spektralkanäle untersuchen\n\nFührt verschiedene Messungen durch mit unterschiedlichen Lichtquellen und Materialien und interpretiert die Ausgabe des bargraph.py.\nStudiert den Code und versucht die Funktionsweise zu verstehen.\n\n\npython bargraph.py \nSetting white point baseline.\n\nHold a white sheet of paper ~5cm in front of the sensor and press a key...\n\nBaseline set. Press a key to continue...   \n\n\n\nBeispiel Ausgabe von bargraph.py Spectrometer Bar Graph\n\n\n\n\n\n\nAMS OSRAM Group. (2022). Datasheet AS7262 6-Channel Visible Spectral_ID Device with Electronic Shutter and Smart Interface. AMS OSRAM Group.\n\n\nJensen, K. (2020). White Paper Chip-scale Spectral Sensing: Understanding the New Uses for Ultra-Precise Light-Source Measurement (S. 10) [White {{Paper}}]. AMS.\n\n\nSliney, D. H. (2016). What Is Light? The Visible Spectrum and Beyond. Eye, 30(2), 222–229. https://doi.org/10.1038/eye.2015.252",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Spektralmessung</span>"
    ]
  },
  {
    "objectID": "E02_Spektralmessung.html#footnotes",
    "href": "E02_Spektralmessung.html#footnotes",
    "title": "5  Spektralmessung",
    "section": "",
    "text": "Nicht vergessen zuerst die korrekte virtuelle Environment mit den installierten Libraries über source ~/.env/bin/activate zu starten↩︎",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Spektralmessung</span>"
    ]
  },
  {
    "objectID": "E03_Bewegungsmessung.html",
    "href": "E03_Bewegungsmessung.html",
    "title": "6  Bewegungsmessung",
    "section": "",
    "text": "Einführung\nZiel dieser Übung ist es Bewegungsmessung mit inertialen Messeinheiten (IMU) über den ICM20948 Bewegungssensor kennen zu lernen und die Sensordaten auszulesen und testen. Der ICM20948 ist ein 9DoF Bewegungssensor, der über eine I2C Schnittstelle mit dem Raspberry Pi verbunden wird und einer Python Library angesteuert werden kann.\nUnterlagen:  E03_Bewegungsmessung.zip\nVorbereitung",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Bewegungsmessung</span>"
    ]
  },
  {
    "objectID": "E03_Bewegungsmessung.html#einführung",
    "href": "E03_Bewegungsmessung.html#einführung",
    "title": "6  Bewegungsmessung",
    "section": "",
    "text": "Schaut das Video zur Funktionsweise von MEMS Bewegungssensoren\n\nVideo: How MEMS Accelerometer Gyroscope Magnetometer Work (bis Minute 2:50), sowie folgendes\nVideo: Bosch Funktionsprinzip eines Beschleunigungssensors\n\nStudiere das Datenblatt zum ICM-20948 (InvenSense, 2021)\n\nIn welchen Temperaturbereichen kann der Sensor eingesetzt werden?\n\nInstalliere auf deinem Smartphone die Applikation phyphox und teste die Beschleunigungssensoren deines Smartphones.\n\n\n\n\n\nUnterlagen\n\n\n\n\n\nProdukt\nICM20948 Breakout\n\n\nDatenblatt\nICM 20948\n\n\nGitHub\nicm20948-python",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Bewegungsmessung</span>"
    ]
  },
  {
    "objectID": "E03_Bewegungsmessung.html#beschleunigungssensoren-imu",
    "href": "E03_Bewegungsmessung.html#beschleunigungssensoren-imu",
    "title": "6  Bewegungsmessung",
    "section": "Beschleunigungssensoren IMU",
    "text": "Beschleunigungssensoren IMU\nBeschleunigungssensoren, oder inertiale Messeinheit (inertial measurement unit IMU) messen die Beschleunigung von Objekten mit dem Messprinzip der Trägheit und erfassen die Kraft die auf die Masse des Objekt wirkt, wenn dieses beschleunigt wird.\nFür die Erfassung der sechs kinematischen Freiheitsgrade werden drei Achsen der Beschleunigung (Accelerometer) und drei Achsen der Rotation (Gyroskop) gemessen, die die Beschleunigungsmessung und Winkelgeschwindigkeit der Drehraten ausgeben. Für die Erfassung der Orientierung im Raum wird ein Magnetometer eingesetzt, welches die Ausrichtung des Objekts im Magnetfeld der Erde misst, um die Ausrichtung im Raum zu bestimmen. Wenn alle drei Sensoren kombiniert werden, spricht man von 9DoF Motion Sensoren, der neun Freiheitsgrade (9 Degrees of Freedom) misst.\nBeschleunigungssensoren werden in vielen Anwendungen eingesetzt, wie z.B. in der Automobilindustrie (Auslösen von Airbags), der Luft- und Raumfahrt, der Medizintechnik (Beschleunigungssensoren in Herzschrittmachern) und der Unterhaltungselektronik (Smartphones für die Ausrichtung des Bildschirms).",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Bewegungsmessung</span>"
    ]
  },
  {
    "objectID": "E03_Bewegungsmessung.html#icm20948-9dof-motion-sensor",
    "href": "E03_Bewegungsmessung.html#icm20948-9dof-motion-sensor",
    "title": "6  Bewegungsmessung",
    "section": "ICM20948 9DoF Motion Sensor",
    "text": "ICM20948 9DoF Motion Sensor\nDer ICM-20948 von TDK InvenSense (Abb. 6.1) ist ein 9-Achsen MEMS Bewegungssensor, mit einem 3-Achsen Gyroskop, einem 3-Achsen Beschleunigungssensor und einem 3-Achsen Magnetometer und sehr geringem Stromverbrauch. Er enthält zwei Chip, einen für die Bewegungsmessung mit Gyroskop und Beschleunigungssensor und einen zweiten für das Magnetometer.\nMEMS sind mikroelektromechanische Systeme, die aus mikroskopisch kleinen mechanischen und elektrischen Komponenten bestehen. Diese werden meist aus Silicium hergestellt und sind im Falle von Beschleunigungssensoren sehr kleine Massen, die sich bei Beschleunigung bewegen und die Änderung der elektrischen Kapazität messen.\n9DoF Motion Accelero-, Gyro-, Magnetometer\n\n±2/±4/±8/±16 g 3-axis accelerometer\n±250/±500/±1000/±2000 DPS (degrees per second) 3-axis gyroscope\n3-axis compass with wide range up to ±4900 μT\nPython, C Library\nI2C interface (address: 0x68 or0x69)\nQw/ST (Qwiic/STEMMA QT) connector\nI2C interface (address 0x68/0x69 (cut trace))\n\n\n\n\n\n\n\nAbb. 6.1: a) schematische Darstellung eines MEMS Beschleunigungssensors Quelle: Bosch, b) raw, pitch, roll bei Flugzeugen, c) ICM-20948 Breakout von Pimoroni, d) Orientierung von IMU Sensoren.",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Bewegungsmessung</span>"
    ]
  },
  {
    "objectID": "E03_Bewegungsmessung.html#übungsaufbau",
    "href": "E03_Bewegungsmessung.html#übungsaufbau",
    "title": "6  Bewegungsmessung",
    "section": "Übungsaufbau",
    "text": "Übungsaufbau\n\nSchliesse den Raspberry Pi an Monitor, Keyboard und Maus an oder verbinde Dich mit diesem über SSH (und SFTP).\nErstelle auf dem Raspberry Pi im Documents Ordner einen neuen Ordner ICM20948, in welchem Du Änderungen und neue Dateien für diese Übung speichern kannst.\nSchliesse den Sensor ICM20948 an den Raspberry Pi über die Breakout Garden I2C Schnittstelle korrekt an (siehe E01 Luftqualität), so dass die Beschriftung der Anschlüsse am Sensor und bei der Schnittstelle übereinstimmen.\nKontrolliere mit dem Befehl i2cdetect -y 1 ob der Raspberry Pi mit dem Sensor verbunden ist. Der Sensor sollte auf der Adresse 0x68 erkannt werden.\nAktiviere die virtuelle Environment von Python mit source ~/.env/bin/activate und kontrolliere, ob die Library icm20948 installiert ist mit python -c \"import icm20948\". Bei einer Fehlermeldung muss die Library in der aktivierten virtuellen Environment mit pip install icm20948 installiert werden.\n\nWechsle in den Ordner Documents und kopiere mit folgenden Befehlen die Library auf Deinen Raspberry Pi.\ncd Documents\ngit clone https://github.com/pimoroni/icm20948-python\ncd icm20948-python/examples",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Bewegungsmessung</span>"
    ]
  },
  {
    "objectID": "E03_Bewegungsmessung.html#aufgabe-1-bewegungsmessungen-durchführen",
    "href": "E03_Bewegungsmessung.html#aufgabe-1-bewegungsmessungen-durchführen",
    "title": "6  Bewegungsmessung",
    "section": "Aufgabe 1: Bewegungsmessungen durchführen",
    "text": "Aufgabe 1: Bewegungsmessungen durchführen\nTeste das Beispiel read-all.py im Ordner examples. Dieses Beispiel gibt die Messungen der einzelnen Bewegungsmessungen aus, der Beschleunigung, Winkelgeschwindigkeit und Orientierung mit dem Accelerometer, Gyrometer und Magnetometer.\nStartet das Script mit python read-all.py1. Mit Ctrl+c kann das Script wieder gestopppt werden. Die Ausgabe sollte in etwa so aussehen (gekürzt):\npython read-all.py\nread-all.py\nReads all ranges of movement: accelerometer, gyroscope and compass heading.\nPress Ctrl+C to exit!\n\nAccel: 01.01 -0.02 00.01\nGyro:  -0.42 01.73 00.01\nMag:   -86.85 57.45 34.05\n\nAccel: 01.01 -0.02 00.02\nGyro:  -0.40 01.50 -0.16\nMag:   -85.35 55.50 34.80\nFolgendes Code Snippet zeigt eine gekürzte Version des read-all.py Python Beispiels für die Ausgabe der Beschleunigungsmessung.\n#!/usr/bin/env python\nimport time\nfrom icm20948 import ICM20948\n\nimu = ICM20948()\n\nwhile True:\n1    x, y, z = imu.read_magnetometer_data()\n2    ax, ay, az, gx, gy, gz = imu.read_accelerometer_gyro_data()\n\n3    print(\"\"\"\nAccel: {:05.2f} {:05.2f} {:05.2f}\nGyro:  {:05.2f} {:05.2f} {:05.2f}\nMag:   {:05.2f} {:05.2f} {:05.2f}\"\"\".format(\n        ax, ay, az, gx, gy, gz, x, y, z\n        ))\n\n4    time.sleep(0.25)\n\n1\n\nAuslesen des Magnetometers (x,y,z)\n\n2\n\nAuslesen des Accelerometers (ax,ay,az) und Gyrometers (gx,gy,gz)\n\n3\n\nMesswerte auf der Konsole ausgeben\n\n4\n\nWarten 0.25 Sekunden (damit die Ausgabe nicht zu schnell ist)\n\n\n\nÜbung 6.1 Bewegungsmessung\n\n\nFühre das Beispiel read-all.py aus und beobachte die Messwerte.\nVersuche den Sensor jeweils leicht in eine Richtung zu bewegen, zu drehen, zu kippen und beobachte die Messwerte.\nVersuche den Sensor zu leicht zu schütteln und beobachte die Messwerte.\nVergleiche die Messwerte mit den Messwerten deines Smartphones mit der App phyphox.\nVersucht zu eruieren wie die Achsen orientiert sind und vergleicht mit anderen Gruppen.\nSchreibe die Messwerte in eine Datei und visualisiere diese mit einem Plot, modifiziere dazu das Beispiel read-all.py und speichere die Datei als read-csv.py, so dass die Messungen zeilenweise mit einem Separator gespeichert werden. Ausgaben aus einem Plot können mit dem Befehl python read-csv.py &gt; imu_horizontal.csv in eine Datei geschrieben werden. Nun könnt ihr verschiedene Versuche mit der IMU durchführen und in einer Datei speichern. Die Datei könnt ihr beispielsweise mit LibreOffice Calc oder Excel öffnen und die Daten visualisieren.",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Bewegungsmessung</span>"
    ]
  },
  {
    "objectID": "E03_Bewegungsmessung.html#aufgabe-2-magnetometer",
    "href": "E03_Bewegungsmessung.html#aufgabe-2-magnetometer",
    "title": "6  Bewegungsmessung",
    "section": "Aufgabe 2: Magnetometer",
    "text": "Aufgabe 2: Magnetometer\nDas Beispiel bargraph.py zeigt die Messwerte des Magnetometers in einem Balkendiagramm an und zeigt die Orientierung des Sensors an je nach dem über welche Achse gemessen wird. Der Befehl python bargraph.py --help zeigt die Optionen des Skripts an.\nDie Ausgabe sollte für die Option --graph in etwa so aussehen:\npython bargraph.py --graph\nbargraph.py - Convert raw values to heading\n\nRotate the sensor through 360 degrees to calibrate.\n\nPress Ctrl+C to exit!\n\n043.5 █████████████                                                                                                     \n\nÜbung 6.2 Bar graph\n\nKalibriere den Sensor und vergleiche die Orientierung des Sensors mit den Himmelsrichtungen\nVergleiche die Ausgaben auch mit der Orientierung des Smartphones und den Messwerten der App phyphox.\nStudiert den Code und versucht die Funktionsweise zu verstehen.\n\n\n\n\n\n\nInvenSense, T. (2021). ICM-20948 World’s Lowest Power 9-Axis MEMS MotionTracking™ Device.",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Bewegungsmessung</span>"
    ]
  },
  {
    "objectID": "E03_Bewegungsmessung.html#footnotes",
    "href": "E03_Bewegungsmessung.html#footnotes",
    "title": "6  Bewegungsmessung",
    "section": "",
    "text": "Nicht vergessen zuerst die korrekte virtuelle Environment mit den installierten Libraries über source ~/.env/bin/activate zu starten↩︎",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Bewegungsmessung</span>"
    ]
  },
  {
    "objectID": "E04_Distanzmessung.html",
    "href": "E04_Distanzmessung.html",
    "title": "7  Distanzmessung",
    "section": "",
    "text": "Einführung\nZiel dieser Übung ist es Distanzmessungen mit dem VL53L5CX Sensor kennen zu lernen und die Sensordaten auszulesen und testen. Der VL53L5CX ist ein 8x8 Time of Flight (ToF) Array Sensor, der über eine I2C Schnittstelle mit dem Raspberry Pi verbunden wird und einer Python Library angesteuert werden kann.\nUnterlagen:  E04_Distanzmessung.zip\nVorbereitung",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Distanzmessung</span>"
    ]
  },
  {
    "objectID": "E04_Distanzmessung.html#einführung",
    "href": "E04_Distanzmessung.html#einführung",
    "title": "7  Distanzmessung",
    "section": "",
    "text": "Schaut folgende von Video von Adafruit Industries zur Funktionsweise des VL53L5CX Sensors an: EYE ON NPI - ST VL53L5CX Time-of-Flight Ranging Sensor\nStudiere das Datenblatt zum VL53L5CX (STMicroelectronics, 2021), sowie die Application Note (STMicroelectronics, 2023)\n\nIn welchen Temperaturbereichen kann der Sensor eingesetzt werden?\nWelches ist die höchste Abtastrate für die Distanzfeldmessungen?\nWas sind Anwendungsgebiete für diesen Sensor?\n\n\n\n\n\n\nUnterlagen\n\n\n\n\n\nProdukt\nVL53L5CX Breakout\n\n\nDatenblatt\nVL53L5CX\n\n\nGitHub\nvl53l5cx-python",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Distanzmessung</span>"
    ]
  },
  {
    "objectID": "E04_Distanzmessung.html#vl53l5cx-8x8-time-of-flight-tof-array-sensor",
    "href": "E04_Distanzmessung.html#vl53l5cx-8x8-time-of-flight-tof-array-sensor",
    "title": "7  Distanzmessung",
    "section": "VL53L5CX 8x8 Time of Flight (ToF) Array Sensor",
    "text": "VL53L5CX 8x8 Time of Flight (ToF) Array Sensor\nDer VL53L5CX ist hochentwickelter Distanzsensor mit einer 8x8-Multizonenmessung und einem großen Sichtfeld, ideal für Roboter und fortschrittliche Bewegungserkennung. Der mit die Entfernung mit Time of Flight (ToF), also mit der Laufzeit von Licht, indem er einen Infrarotlaser mit geringer Leisten auf ein Ziel schickt und die Zeit misst, die das Licht benötigt, um zurückzukehren.\nDieser Sensor hat eine hohe Genauigkeit und Abtastfrequenz (bis zu 60 Hz) und einen großen Erfassungsbereich (von 2 cm bis 4 m). Besonders interessant ist, dass der Sensor nicht nur eine Messung durchführt, sondern eine 8x8 Matrix mit Messwerten zurückgibt. Das bedeutet, das Bewegungen aus bestimmten Richtungen erkannt werden können oder der Sensor benutzt werden kann um Kollisionen zu vermeiden oder Objekte zu verfolgen ohne dass mehrere Sensoren benötigt werden.\nVL53L5CX 8x8 Time of Flight (ToF) Array Sensor Breakout\n\n8x8 Multizone readings\nDistance 2cm - 4m\nI2C interface, with address: 0x52\nPython, C Library\n\n\n\n\n\n\n\nAbb. 7.1: links: VL53L5CX Breakout von Pimoroni, rechts: schematische Darstellung TOF Moduls Quelle: STMicroelectronics (2023)",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Distanzmessung</span>"
    ]
  },
  {
    "objectID": "E04_Distanzmessung.html#übungsaufbau",
    "href": "E04_Distanzmessung.html#übungsaufbau",
    "title": "7  Distanzmessung",
    "section": "Übungsaufbau",
    "text": "Übungsaufbau\n\nSchliesse den Raspberry Pi an Monitor, Keyboard und Maus an oder verbinde Dich mit diesem über SSH (und SFTP).\nErstelle auf dem Raspberry Pi im Documents Ordner einen neuen Ordner VL53L5CX, in welchem Du Änderungen und neue Dateien für diese Übung speichern kannst.\nSchliesse den Sensor VL53L5CX an den Raspberry Pi über die Breakout Garden I2C Schnittstelle korrekt an (siehe E01 Luftqualität), so dass die Beschriftung der Anschlüsse am Sensor und bei der Schnittstelle übereinstimmen.\nKontrolliere mit dem Befehl i2cdetect -y 1 ob der Raspberry Pi mit dem Sensor verbunden ist. Der Sensor sollte auf der Adresse 0x29 erkannt werden.\nAktiviere die virtuelle Environment von Python mit source ~/.env/bin/activate und kontrolliere, ob die Libraries vl53l5cx_ctypes und st7789 installiert sind mit python -c \"import st7789\" und python -c \"import vl53l5cx_ctypes\". Bei einer Fehlermeldung muss die jeweilige fehlende Library in der aktivierten virtuellen Environment mit pip install st7789 oder pip install vl53l5cx_ctypes installiert werden.\n\nWechsle in den Ordner Documents und kopiere mit folgenden Befehlen die Library auf Deinen Raspberry Pi.\ncd Documents\ngit clone https://github.com/pimoroni/vl53l5cx-python\ncd vl53l5cx-python/examples",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Distanzmessung</span>"
    ]
  },
  {
    "objectID": "E04_Distanzmessung.html#aufgabe-1-distanzmessung-konsole",
    "href": "E04_Distanzmessung.html#aufgabe-1-distanzmessung-konsole",
    "title": "7  Distanzmessung",
    "section": "Aufgabe 1: Distanzmessung Konsole",
    "text": "Aufgabe 1: Distanzmessung Konsole\nTeste das Beispiel test.py im Ordner examples. Dieses Beispiel liest die Werte der 8x8 Time of Flight Messung aus mit Werten zu motion, distance, reflectance und status aus.\n\nDas Script startet langsam, da die Library jeweils die Firmware beim Starten lädt.\n\nStartet das Script mit python test.py. Mit Ctrl+C kann das Script wieder gestopppt werden. Die Ausgabe sollte in etwa so aussehen (gekürzt):\npython3 test.py \nUploading firmware, please wait...\nDone!\n[[  36   26 2356  543]\n [  38   62 1943 3847]\n [  27   68  530 6744]\n [  14   18   66  458]] [[1254  308  406 2042  365  377  314  237]\n [1275  351  397  413  404  403  354  228]\n [1297  357  375  432  427  422  391  241]\n [1250  348  385  389  415  437  398  315]\n [1273  358  358  385  405  429  400  363]\n [1238  336 2240  368  424  417  379  336]\n [1262  226 2215  180  188  218  202  190]\n [ 108  110  113  117  116  120  120  124]] [[23  1  2 30 11  8 27 41]\n [16  1  3  4  4 17 43 35]\n [23  1  2  6  5 21 58 32]\n [21  1  2  4  6 32 62 52]\n [27  1  3  5  9 36 65 71]\n [27  1 59  5 16 47 52 46]\n [26  1 39  6  9 20 20 21]\n [13 13 14 14 15 16 17 20]] [[False False False  True False False  True  True]\n [ True False False False False  True  True  True]\n [ True False False False False  True  True  True]\n [ True False False False False  True  True  True]\n [ True False False False False  True  True  True]\n [ True False  True False  True  True  True  True]\n [ True False False  True  True  True  True  True]\n [ True  True  True  True  True  True  True  True]]\nFolgendes Code Snippet zeigt eine gekürzte Version des test.py Python Beispiels für die Ausgabe der Distanzmatrix.\nimport time\nimport numpy\nimport vl53l5cx_ctypes as vl53l5cx\nfrom vl53l5cx_ctypes import STATUS_RANGE_VALID, STATUS_RANGE_VALID_LARGE_PULSE\n\nprint(\"Uploading firmware, please wait...\")                                      \n1vl53 = vl53l5cx.VL53L5CX()\nprint(\"Done!\")                                                                   \n2vl53.set_resolution(8 * 8)\nvl53.enable_motion_indicator(8 * 8)\n# vl53.set_integration_time_ms(50)\n# Enable motion indication at 8x8 resolution\nvl53.enable_motion_indicator(8 * 8)\n# Default motion distance is quite far, set a sensible range\n# eg: 40cm to 1.4m\nvl53.set_motion_distance(400, 1400)\n3vl53.start_ranging()\n\nwhile True:\n    if vl53.data_ready():\n4        data = vl53.get_data()\n        # 2d array of motion data (always 4x4?)\n        motion = numpy.flipud(numpy.array(data.motion_indicator.motion[0:16]).reshape((4, 4)))\n        # 2d array of distance\n        distance = numpy.flipud(numpy.array(data.distance_mm).reshape((8, 8)))\n        # 2d array of reflectance\n        reflectance = numpy.flipud(numpy.array(data.reflectance).reshape((8, 8)))\n        # 2d array of good ranging data\n        status = numpy.isin(numpy.flipud(numpy.array(data.target_status).reshape((8, 8))), (STATUS_RANGE_VALID, STATUS_RANGE_VALID_LARGE_PULSE))\n        print(motion, distance, reflectance, status)\n    time.sleep(0.1)\n\n1\n\nSensor initialisieren und Firmware laden\n\n2\n\nSensor konfigurieren (Auflösung, Bewegungserkennung, Messbereich)\n\n3\n\nMessung initialisieren\n\n4\n\nWarten 0.1 Sekunden (damit die Ausgabe nicht zu schnell ist)\n\n\n\nÜbung 7.1 Bewegungsmessung\n\nFühre das Beispiel test.py aus und beobachte die Messwerte.\nFühre unterschiedliche Tests durch, indem Du ein Objekt vor den Sensor hältst und bewegst.\nVergleiche die Messwerte und kontrolliere die gemessenen Distanzen.\nUntersuche die einzelnen Matrizen und versuche die Bedeutung der einzelnen Werte zu verstehen.",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Distanzmessung</span>"
    ]
  },
  {
    "objectID": "E04_Distanzmessung.html#aufgabe-2-distanzmessung-mit-lcd-bildschirm",
    "href": "E04_Distanzmessung.html#aufgabe-2-distanzmessung-mit-lcd-bildschirm",
    "title": "7  Distanzmessung",
    "section": "Aufgabe 2: Distanzmessung mit LCD Bildschirm",
    "text": "Aufgabe 2: Distanzmessung mit LCD Bildschirm\nFolgende Aufgabe nutzt den 1.54” LCD Bildschirm mit einer 240x240 Pixel Auflösung. Die Library vl53l5cx_ctypes enthält mehrere Beispiele, die die Distanzmatrizen für die Distanz-, Bewegungs- und Reflektanzmessung auf dem Bildschirm anzeigen. Die Beispiele sind im Ordner examples zu finden.\n\n\n\n\n\n\nAbb. 7.2: Aufbau der Versuchsanordnung für die Distanzmessung mit dem LCD Bildschirm montiert im dem hinteren SPI Slot\n\n\n\nVorbereitung\n\nKontrolliert mit python -c \"import st7789\" ob die Library st7789 installiert ist. Testet auch, ob die Bibliotheken numpy und matplotlib installiert sind und installiert diese ansonsten mit sudo apt install python3-matplotlib python3-numpy.\nKontrolliere, ob der Raspberry Pi den Breakout Garden HAT mit den 2 SPI Anschlüssen und 4 I2C Anschlüssen bestückt ist (Abb. 7.2).\nMontiere den Bildschirm im hinteren SPI Slot des Breakout Garden HATs wie in Abb. 7.2, da er sonst die Messung des VL53L5CX Sensors verdeckt.\n\nFührt nun folgende Scripts aus und beobachtet die Ausgabe auf dem LCD Bildschirm. Auch hier braucht es etwas Geduld, da die Firmware beim Starten geladen wird.\n\npython distance_240x240_lcd.py\npython motion_240x240_lcd.py\npython reflectance_240x240_lcd.py\npython object_tracking.py\n\n\nÜbung 7.2 Distanzmessung\n\nFühre die Beispiele aus und beobachte die Ausgabe auf dem LCD Bildschirm.\nUntersuche die einzelnen Matrizen und versuche die Bedeutung der einzelnen Werte zu verstehen.\nFühre unterschiedliche Tests durch, indem Du ein Objekt vor den Sensor hälst und bewegst.\nWas passiert wenn Du ein Objekt vor den Sensor hältst? Ist die Form erkennbar?\nWas passiert wenn Du ein Objekt vor den Sensor hältst und bewegst?\nStudiere den Code der Beispiele und versuche die Funktionsweise zu verstehen.\nÜberlege Dir Anwendungsfälle für diesen Sensor allgemein und im speziellen für die Geomatik.\n\n\n\n\n\n\nSTMicroelectronics. (2021). VL53L5CX - Datasheet - Time-of-Flight 8x8 Multizone Ranging Sensor with Wide Field of View.\n\n\nSTMicroelectronics. (2023). Description of the Fields of View of STMicroelectronics’ Time-of-Flight Sensors.",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Distanzmessung</span>"
    ]
  },
  {
    "objectID": "E05_Thermalmessung.html",
    "href": "E05_Thermalmessung.html",
    "title": "8  Thermale Aufnahmen",
    "section": "",
    "text": "Einführung\nZiel dieser Übung ist es thermale Kamera mit der MLX90640 Kamera kennen zu lernen und die thermalen Bilddaten auszulesen und testen. Die MLX90640 ist eine weitwinkel Kamera mit einer Auflösung von 24x32 Pixel. Sie wird über eine I2C Schnittstelle mit dem Raspberry Pi verbunden und kann über eine Python Library angesteuert werden.\nUnterlagen:  E05_Thermalkamera.zip\nVorbereitung",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Thermale Aufnahmen</span>"
    ]
  },
  {
    "objectID": "E05_Thermalmessung.html#einführung",
    "href": "E05_Thermalmessung.html#einführung",
    "title": "8  Thermale Aufnahmen",
    "section": "",
    "text": "Schaut folgende von Video von Melexis zur Funktionsweise der MLX90640 Thermalkamera an: Far Infrared (IR) Thermal Sensor Array 32x24 RES (MLX90640)\nStudiere das Datenblatt zum VL53L5CX (Melexis, 2019) und beantworte folgende Fragen:\n\nIn welchen Temperaturbereichen kann der Sensor eingesetzt werden?\nWelches ist die höchste Abtastrate für die Distanzfeldmessungen?\nWas sind Anwendungsgebiete für diesen Sensor?\n\n\n\n\n\n\nUnterlagen\n\n\n\n\n\nProdukt\nMLX90640 Breakout\n\n\nDatenblatt\nMLX90640\n\n\nGitHub\nmlx90640-library, Adafruit MLX90640",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Thermale Aufnahmen</span>"
    ]
  },
  {
    "objectID": "E05_Thermalmessung.html#mlx90640-thermalkamera",
    "href": "E05_Thermalmessung.html#mlx90640-thermalkamera",
    "title": "8  Thermale Aufnahmen",
    "section": "MLX90640 Thermalkamera",
    "text": "MLX90640 Thermalkamera\nDer MLX90640 ist eine Thermalkamera mit einer Auflösung von 32x24 Pixel mit einem Sichtfeld von 55°. Die Kamera misst in einem Temperaturbereich von -40° - 300°C mit einer Genauigkeit von etwa 1°C und mit einer Aufnahmerate von bis zu 64 FPS. Die Anwendungsbereiche sind vielfältig, von der Temperatur der Kaffeetasse, Hitzeentwicklung in elektronischen Geräten bis hin zur Überwachung von Gebäuden und Anlagen.\nMLX90640 Thermal Camera\n\nMelexis MLX90640 far-infrared sensor array\nBrennweite: 55°\n32x24 pixels\nI2C interface (address 0x33)\n\n\n\n\n\n\n\nAbb. 8.1: links: MLX90640 Thermalkamera, oben: schematische Darstellung der Kamera und ihrer Anschlüsse rechts: Pixelpositionaufbau Quelle: STMicroelectronics (2023)",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Thermale Aufnahmen</span>"
    ]
  },
  {
    "objectID": "E05_Thermalmessung.html#übungsaufbau",
    "href": "E05_Thermalmessung.html#übungsaufbau",
    "title": "8  Thermale Aufnahmen",
    "section": "Übungsaufbau",
    "text": "Übungsaufbau\n\nSchliesse den Raspberry Pi an Monitor, Keyboard und Maus an oder verbinde Dich mit diesem über SSH (und SFTP).\nErstelle auf dem Raspberry Pi im Documents Ordner einen neuen Ordner MLX90640, in welchem Du Änderungen und neue Dateien für diese Übung speichern kannst.\nSchliesse den Sensor MLX90640 an den Raspberry Pi über die Breakout Garden I2C Schnittstelle korrekt an (siehe E01 Luftqualität), so dass die Beschriftung der Anschlüsse am Sensor und bei der Schnittstelle übereinstimmen.\nKontrolliere mit dem Befehl i2cdetect -y 1 ob der Raspberry Pi mit dem Sensor verbunden ist. Der Sensor sollte auf der Adresse 0x33 erkannt werden.\nAktiviere die virtuelle Environment von Python mit source ~/.env/bin/activate und kontrolliere, ob die Libraries adafruit-blinka,adafruit-circuitpython-mlx90640 und RPI.GPIO installiert sind mit python -c \"import adafruit-blinka\", python -c \"import adafruit-circuitpython-mlx90640\" und python -c \"RPI.GPIO\". Bei einer Fehlermeldung müssen die fehlenden Libraries in der aktivierten virtuellen Environment mit pip install adafruit-blinka adafruit-circuitpython-mlx90640 RPI.GPIO installiert werden.\nDie Python Scripts für die Thermalkamera werden in den Unterlagen zu dieser Übung bereitgestellt.\n\nWechsle in den Ordner Documents und kopiere in diesen den Ordner MLX90640 mit den Code Beispielen.",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Thermale Aufnahmen</span>"
    ]
  },
  {
    "objectID": "E05_Thermalmessung.html#aufgabe-1-punktuelle-temperaturmessung",
    "href": "E05_Thermalmessung.html#aufgabe-1-punktuelle-temperaturmessung",
    "title": "8  Thermale Aufnahmen",
    "section": "Aufgabe 1: Punktuelle Temperaturmessung",
    "text": "Aufgabe 1: Punktuelle Temperaturmessung\nTeste das Beispiel average_temperature.py im Ordner examples. Dieses Beispiel liest die Werte aus der Matrix der Thermalkamera und gibt den Mittelwert der Temperatur aus. Die Ausgabe sollte in etwa so aussehen (gekürzt):\npython average_temperature.py \nAverage MLX90640 Temperature: 23.6C (74.5F)\nFolgendes Code Snippet zeigt eine gekürzte Version des average_temperature.py Python Beispiels für die Ausgabe der Distanzmatrix.\nimport time,board,busio\nimport numpy as np\nimport adafruit_mlx90640\n\n1i2c = busio.I2C(board.SCL, board.SDA)\nmlx = adafruit_mlx90640.MLX90640(i2c)\nmlx.refresh_rate = adafruit_mlx90640.RefreshRate.REFRESH_2_HZ\n\n2frame = np.zeros((24*32,))\nwhile True:\n    try:\n3        mlx.getFrame(frame)\n        break\n    except ValueError:\n4        continue\n\n# print out the average temperature from the MLX90640\nprint('Average MLX90640 Temperature: {0:2.1f}C ({1:2.1f}F)'.\\   \n5      format(np.mean(frame),(((9.0/5.0)*np.mean(frame))+32.0)))\n\n1\n\nSetup von I2C, Initialisierung des MLX90640 Sensors und Setzen der Abtastrate auf 2 Hz\n\n2\n\nNumpy Array für das Speichern der 768 Temperaturwerte (24x32 Pixel) erstellen\n\n3\n\nMLX Temperaturwerte in das Numpy Array speichern\n\n4\n\nFalls ein Fehler eintritt, nochmals versuchen den Sensor auszulesen\n\n5\n\nTemperaturmittelwert ausgeben\n\n\n\nÜbung 8.1 Einzelne Temperaturmessung\n\nFühre das Beispiel average_temperature.py aus und beobachte die Messwerte.\nTeste das Script mit unterschiedlichen warmen Objekten (z.B. Kaffeetasse, Hand, etc.).",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Thermale Aufnahmen</span>"
    ]
  },
  {
    "objectID": "E05_Thermalmessung.html#aufgabe-2-thermale-aufnahme-mit-lcd-bildschirm",
    "href": "E05_Thermalmessung.html#aufgabe-2-thermale-aufnahme-mit-lcd-bildschirm",
    "title": "8  Thermale Aufnahmen",
    "section": "Aufgabe 2: Thermale Aufnahme mit LCD Bildschirm",
    "text": "Aufgabe 2: Thermale Aufnahme mit LCD Bildschirm\nFolgende Aufgabe nutzt den 1.54” LCD Bildschirm mit einer 240x240 Pixel Auflösung. Der Ordner enthält mehrere Beispiele zur Thermalkamera, die die Temperaturmatrix auf dem Bildschirm anzeigen. Die Beispiele sind im Ordner MLX90640 zu finden.\n\n\n\n\n\n\nAbb. 8.2: Aufbau der Versuchsanordnung für die Distanzmessung mit dem LCD Bildschirm montiert im dem hinteren SPI Slot\n\n\n\nVorbereitung\n\nKontrolliert mit python -c \"import st7789\" ob die Library st7789 installiert ist. Installiere die Library mit in der aktivierten virtuellen Environment source ~/.env/bin/activate mit pip install st7789, falls sie nicht installiert ist. Testet auch, ob die Bibliotheken numpy und matplotlib installiert sind und installiert diese ansonsten mit sudo apt install python3-matplotlib python3-numpy.\nKontrolliere, ob der Raspberry Pi den Breakout Garden HAT mit den 2 SPI Anschlüssen und 4 I2C Anschlüssen bestückt ist (Abb. 8.2).\nMontiere den Bildschirm im vorderen SPI Slot des Breakout Garden HATs wie in Abb. 8.2, oder passe das Script, an so dass die Werte der hinteren SPI Schnittstelle verwendet werden.\nTeste die Beispiele im Ordner MLX90640 und beobachte die Ausgabe auf dem LCD Bildschirm.\n\n\nÜbung 8.2 Experimente mit der Thermalkamera und dem LCD Bildschirm\n\nTeste mit unterschiedlichen Objekten die Temperaturmessung und beobachte die Ausgabe auf dem LCD Bildschirm.\nWie gut lassen sich Objekte mit unterschiedlichen Temperaturen unterscheiden?\nWie gut lassen sich Objekte erkennen, die sich in der Temperatur nur wenig oder stark unterscheiden?\nStudiere den Code der Beispiele und versuche die Funktionsweise zu verstehen.\nÜberlege Dir, wie Du die Beispiele erweitern könntest.\n\n\n\n\n\n\nMelexis. (2019). MLX90640 32x24 IR Array Datasheet.\n\n\nSTMicroelectronics. (2023). Description of the Fields of View of STMicroelectronics’ Time-of-Flight Sensors.",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Thermale Aufnahmen</span>"
    ]
  },
  {
    "objectID": "E06_Biometrie.html",
    "href": "E06_Biometrie.html",
    "title": "9  Biometrie",
    "section": "",
    "text": "Einführung\nZiel dieser Übung ist es biometrische Messungen mit dem MAX30101 Sensor durchzuführen und den Sensor in seiner funktionsweise zu untersuchen. Der MAX30101 ist ein Sensor zur Messung der Herzfrequenz und der Sauerstoffsättigung im Blut und ein Rauch-/Partikelsensor. Er verfügt über eine I2C Schnittstelle und kann über eine Python Library angesteuert werden.\nUnterlagen:  E06_Biometrie.zip\nVorbereitung",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Biometrie</span>"
    ]
  },
  {
    "objectID": "E06_Biometrie.html#einführung",
    "href": "E06_Biometrie.html#einführung",
    "title": "9  Biometrie",
    "section": "",
    "text": "Schaut Euch folgendes von Video von Peter Charlton zur Funktionsweise der Herzfrequenzmessung an: Photoplethysmography in a minute (and a bit) - Peter Charlton\nStudiere das Datenblatt zum MAX30101 (maxim integrated, 2020)\n\nIn welchen Temperaturbereichen kann der Sensor eingesetzt werden?\nWelches ist die höchste Abtastrate für die Sauerstoffmessungen?\nWas sind Anwendungsgebiete für diesen Sensor?\n\n\n\n\n\n\nUnterlagen\n\n\n\n\n\nProdukt\nMAX30101 Breakout\n\n\nDatenblatt\nMAX30101\n\n\nGitHub\nmax30105-python",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Biometrie</span>"
    ]
  },
  {
    "objectID": "E06_Biometrie.html#max30101-breakout-heart-rate-oximeter-smoke-sensor",
    "href": "E06_Biometrie.html#max30101-breakout-heart-rate-oximeter-smoke-sensor",
    "title": "9  Biometrie",
    "section": "MAX30101 Breakout Heart Rate, Oximeter, Smoke Sensor",
    "text": "MAX30101 Breakout Heart Rate, Oximeter, Smoke Sensor\nDer MAX30101 ist hochentwickelter Herzfrequenz-, Oximeter- und Rauch-/Partikelsensor. Der Sensor verfügt über drei LEDs (rot, grün, IR) und Photodetektoren. Mit der Photoplethysmographie (photoplethysmography PPG) kann über die Farbveränderung der Haut bei jedem Herzschlag dieser detektiert werden, wenn der Sensor leicht auf den Finger gedrückt wird. Der Sensor kann auch dazu benutzt werden um Partikel in der Luft wie rauch zu erkennen, in dem er die Lichtmenge, die von Partikeln in der Luft zurückgeworfen wird misst.\nMAX30101 Breakout - Heart Rate, Oximeter, Smoke Sensor Breakout\n\nMAX30101 - heart rate, oximeter, smoke sensor\nGreen, red, and infra-red LEDs\nPhotodetectors\nAmbient light rejection\nTemperature sensor\n\n\n\n\n\n\n\nAbb. 9.1: links: MAX30101 Breakout von Pimoroni, rechts: funktionale Diagram des MAX30101 Moduls Quelle: maxim integrated (2020)",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Biometrie</span>"
    ]
  },
  {
    "objectID": "E06_Biometrie.html#übungsaufbau",
    "href": "E06_Biometrie.html#übungsaufbau",
    "title": "9  Biometrie",
    "section": "Übungsaufbau",
    "text": "Übungsaufbau\n\nSchliesse den Raspberry Pi an Monitor, Keyboard und Maus an oder verbinde Dich mit diesem über SSH (und SFTP).\nErstelle auf dem Raspberry Pi im Documents Ordner einen neuen Ordner MAX30101, in welchem Du Änderungen und neue Dateien für diese Übung speichern kannst.\nSchliesse den Sensor MAX30101 an den Raspberry Pi über die Breakout Garden I2C Schnittstelle korrekt an (siehe E01 Luftqualität), so dass die Beschriftung der Anschlüsse am Sensor und bei der Schnittstelle übereinstimmen.\nKontrolliere mit dem Befehl i2cdetect -y 1 ob der Raspberry Pi mit dem Sensor verbunden ist. Der Sensor sollte auf der Adresse 0x57 erkannt werden.\nAktiviere die virtuelle Environment von Python mit source ~/.env/bin/activate und kontrolliere, ob die Library vl53l5cx_ctypes installiert ist mit python -c \"import vl53l5cx_ctypes\". Bei einer Fehlermeldung muss die Library in der aktivierten virtuellen Environment mit pip install vl53l5cx_ctypes installiert werden.\n\nWechsle in den Ordner Documents und kopiere mit folgenden Befehlen die Library auf Deinen Raspberry Pi.\ncd Documents\ngit clone https://github.com/pimoroni/max30105-python\ncd max30105-python/examples",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Biometrie</span>"
    ]
  },
  {
    "objectID": "E06_Biometrie.html#aufgabe-1-biometriemessung-konsole",
    "href": "E06_Biometrie.html#aufgabe-1-biometriemessung-konsole",
    "title": "9  Biometrie",
    "section": "Aufgabe 1: Biometriemessung Konsole",
    "text": "Aufgabe 1: Biometriemessung Konsole\nTeste das Beispiel read-heartbeat.py im Ordner examples. Dieses Beispiel liest die Pulsschläge pro Minute in PPM (beats per minute). Ein erkannter Pulsschlag wird mit einem &lt;3 angezeigt.\nStartet das Script mit python read-heartbeat.py. Mit Ctrl+c kann das Script wieder gestopppt wrden. Die Ausgabe sollte in etwa so aussehen (gekürzt):\npython read-heartbeat.py \nNOTE! This code should not be used for medical diagnosis. \n...\nStarting readings in 10 seconds...\n\n   BPM: 0.00  AVG: 0.00\n   BPM: 0.00  AVG: 0.00\n   BPM: 0.00  AVG: 0.00\n   BPM: 0.00  AVG: 0.00\n   BPM: 45.55  AVG: 45.96\n&lt;3 BPM: 55.75  AVG: 59.90\n   BPM: 55.75  AVG: 59.90\n&lt;3 BPM: 59.64  AVG: 70.65\n   BPM: 59.64  AVG: 70.65\nFolgendes Code Snippet zeigt eine gekürtzte Version des read-heartbeat.py Python Beispiels für die Ausgabe des Herzschlags.\n#!/usr/bin/env python\n\n# NOTE! This code should not be used for medical diagnosis. It's\n# for fun/novelty use only, so bear that in mind while using it.\n\nimport time\nfrom max30105 import MAX30105, HeartRate\n\n1max30105 = MAX30105()\n2max30105.setup(leds_enable=2)\nmax30105.set_led_pulse_amplitude(1, 0.2)\nmax30105.set_led_pulse_amplitude(2, 12.5)\nmax30105.set_led_pulse_amplitude(3, 0)\nmax30105.set_slot_mode(1, 'red')\nmax30105.set_slot_mode(2, 'ir')\nmax30105.set_slot_mode(3, 'off')\nmax30105.set_slot_mode(4, 'off')\n\n3def display_heartrate(beat, bpm, avg_bpm):\n    print(\"{} BPM: {:.2f}  AVG: {:.2f}\".format(\"&lt;3\" if beat else \"  \",\n          bpm, avg_bpm))\n4hr = HeartRate(max30105)\n\n5delay = 10\nprint(\"Starting readings in {} seconds...\\n\".format(delay))\ntime.sleep(delay)\n\ntry:\n6    hr.on_beat(display_heartrate, average_over=4)\nexcept KeyboardInterrupt:\n    pass\n\n1\n\nSensor initialisieren\n\n2\n\nSensor konfigurieren (LED Pulse Amplitude, Slot Mode der LED)\n\n3\n\nFunktion zur Darstellung des Herzschlags in der Konsole\n\n4\n\nInitialisierung des Herzschlagdetektors\n\n5\n\n10 Sekunden warten und dann die Herzschläge ausgeben\n\n6\n\nBei einem erkannten Herzschlag wird die Funktion display_heartrate aufgerufen und der Herzschlag wird über 4 Sekunden gemittelt in der Konsole ausgegeben.\n\n\n\nÜbung 9.1 Pulsmessung\n\nFühre das Beispiel read-heartbeat.py aus und beobachte die Messwerte.\nFühre unterschiedliche Tests durch und behandle den Sensor freundlich.\nVergleiche die Messwerte und kontrolliere die Werte in dem Du den eigenen Puls misst oder mit einem Sportuhr vergleichst.\nStudiere den Code der Beispiele und versuche die Funktionsweise zu verstehen.\n\n\n\n\n\n\nmaxim integrated. (2020). MAX30101 High-Sensitivity Pulse Oximeter and Heart-Rate Sensor for Wearable Health.",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Biometrie</span>"
    ]
  },
  {
    "objectID": "E07_MQTT.html",
    "href": "E07_MQTT.html",
    "title": "10  IoT Monitoring",
    "section": "",
    "text": "Einführung\nEin IoT Datenfluss erstreckt sich über verschiedene Instanzen, die für die einzelnen Prozesse zuständig sind, von der Erfassung von Sensormesswerten im IoT Gerät über die Kommunikation der Messwerte bis zur Datenverarbeitung, Speicherung und Visualisierung (Abb. 10.1). Hierbei können alle Schritte auf einem Gerät durchgeführt werden oder jeder einzelne über ein anderes Gerät oder Server. In der Abbildung aufgezeigt sind typische Softwarekomponenten, die in IoT eingesetzt werden, wie Node-Red für die Datenverarbeitung, die InfluxDB Datenbank, welche für das Speichern von Zeitreihendaten entwickelt wurde und Grafana eine Visualisierungsplattform, die für Messdaten optimiert ist. Es sind Werkzeuge die über ihre graphische Oberfläche einen guten Einstieg ermöglichen, sogenannte low-code Tools, die sich gut eignen für die Entwicklung von Prototypen mit geringem zeitlichen Aufwand. Je nach Anwendung können die einzelnen Prozessschritte auch gut in einer Scriptsprache wie Python durchgeführt oder eine andere Datenbank verwendet werden.\nZiel dieser Übung ist es MQTT näher kennenzulernen und die MQTT Kommunikation mit dem Raspberry Pi zu testen. MQTT ist ein leichtgewichtiges Kommunikationsprotokoll, welches das Publish-Subscribe Muster verwendet und sich gut für die Anwendung in IoT Projekten geeignet.\nUnterlagen:  E07_MQTT.zip",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>IoT Monitoring</span>"
    ]
  },
  {
    "objectID": "E07_MQTT.html#einführung",
    "href": "E07_MQTT.html#einführung",
    "title": "10  IoT Monitoring",
    "section": "",
    "text": "Abb. 10.1: Typischer IoT Datenfluss und Verarbeitung über diverse Instanzen, von dem IoT Gerät mit Sensorik, Datenkommunikation mit MQTT und dem MQTT Broker, zur Datenprozessierung mit Node-Red, Datenspeicherung und und Visalisierung.",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>IoT Monitoring</span>"
    ]
  },
  {
    "objectID": "E07_MQTT.html#übungsaufbau",
    "href": "E07_MQTT.html#übungsaufbau",
    "title": "10  IoT Monitoring",
    "section": "Übungsaufbau",
    "text": "Übungsaufbau\n\nSchliesse den Raspberry Pi an Monitor, Keyboard und Maus an oder verbinde Dich mit diesem über SSH (und SFTP).\nErstelle auf dem Raspberry Pi im Documents Ordner einen neuen Ordner mqtt, in welchem Du Änderungen und neue Dateien für diese Übung speichern kannst.\nSchliesse den Sensor BME688 an den Raspberry Pi über die Breakout Garden I2C Schnittstelle korrekt an (siehe E01 Luftqualität), so dass die Beschriftung der Anschlüsse am Sensor und bei der Schnittstelle übereinstimmen.\nKontrolliere mit dem Befehl i2cdetect -y 1 ob der Raspberry Pi mit dem Sensor verbunden ist. Der Sensor sollte auf der Adresse 0x76 erkannt werden.\nKontrolliere, ob die Library bme680 installiert ist mit python -c \"import bme680\". Installiere die Library mit in der aktivierten virtuellen Environment source ~/.env/bin/activate mit pip install bme680, falls sie nicht installiert ist.\nWechsle in den Ordner Documents und erstelle einen Ordner mqtt für diese Übung.",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>IoT Monitoring</span>"
    ]
  },
  {
    "objectID": "E07_MQTT.html#aufgabe-1-mqtt-kennenlernen",
    "href": "E07_MQTT.html#aufgabe-1-mqtt-kennenlernen",
    "title": "10  IoT Monitoring",
    "section": "Aufgabe 1: MQTT kennenlernen",
    "text": "Aufgabe 1: MQTT kennenlernen\nMosquitto ist eine kompakter open-source Message Broker der Eclipse Foundation, welcher das MQTT Protokoll implementiert und auf Produktionsserver, wie auch auf stromsparenden Geräten wie dem Raspberry Pi eingesetzt werden kann. Wir testen die Kommunikation mit dem MQTT Broker und den Clients auf dem Raspberry Pi. Der Mosquitto Broker ist auf dem Raspberry Pi Image vorkonfiguriert und läuft als Service im Hintegrund. Die Clients mosquitto_pub und mosquitto_sub sind ebenfalls installiert und können für das Testen der Kommunikation MQTT verwendet werden. Mosquitto Dokumentation: https://mosquitto.org/documentation\n\n\n\nMQTT Device publiziert an den MQTT Broker über ein definiertes Topic Messdaten. Der Broker publiziert die Daten über die definierten Topics. Diese werden vom Subscriber abonniert und empfangen mit dem Vorteil, dass keines der Geräte zur gleichen Zeit synchron senden und empfangen muss.\n\n\nErstelle einen Subscriber der für das Topic iot/temperature eine Subscription erstellt.\nmosquitto_sub -h 127.0.0.1 -v -t 'iot/temperature'\nÖffne ein zweite Shell und erstelle einen Publisher für dasselbe Topic\nmosquitto_pub -h 127.0.0.1 -t 'iot/temperature' -m 'Aussentemperatur: 22° Celsius'\n\nMQTT Message\n\nDie MQTT Nachrichten (Messages) bestehen aus einem Topic (Thema) und einer Payload dem Nachrichteninhalt.\n\nMQTT Topics\n\nMQTT verwendet Themen (Topic) und hierarchische Themenebenden getrennt über einem Schrägstrich / ähnlich einem Ordnersystem auf einem Computer. Dies ermöglicht eine Strukturierung und auch Filterung der Messages. Topics sind case-sensitive, sollten nicht mit einem /, $ beginnen und keine Leerzeichen enthalten, sowie kurz und aussagekräftig sein. Filtern von Topics ist mit dem Wildcard + für ein einzelnes Thema und # für alle Themen möglich1.\n\nMQTT Payload\n\nDie Nachrichten (Messages) die über MQTT übertragen werden, werden als Payload bezeichnet. Diese Payload ist nicht an eine bestimmte Struktur gebunden und kann ein Text- oder Binärformat sein. Eine festgelegte Struktur für die Payload ist jedoch sinnvoll für eine reibungslose Datenverarbeitung beispielsweise im JSON Format. Übliche Fromate sind Text, JSON, Binärdaten, Hex Strings oder auch Protocol Buffer.\n\n\n\nÜbung 10.1  \n\nTeste nun den MQTT mit unterschiedlichen Topics und Nachrichten.\nTeste einen weiteren Mosquitto Server auf einem anderen Raspberry Pi und teste die Kommunikation. Hierbei muss die IP Adresse entsprechend angepasst werden.\nEinigt Euch auf einen MQTT Broker und eine Topic-Struktur beispielweise iot/temperature und iot/humidity und publiziert und abonniert Nachrichten. Was fällt Euch auf, wenn Ihr die Nachrichten empfängt?\nWelche Angaben sollten zusätzlich zu den Messwerten in der Payload der Nachrichten enthalten sein?\n\n\nFalls der Mosquitto Brokers und Clients nicht installiert sind, können diese mit folgenden Befehlen installiert werden.\nsudo apt install mosquitto -y\nsudo apt install mosquitto-clients -y\nsudo systemctl enable mosquitto.service\nsudo systemctl status mosquitto\n\nMQTTBox und MQTT Explorer sind zwei MQTT Clients, die für die Entwicklung und das Testen von MQTT Applikationen verwendet werden können. Jedoch scheinen diese nicht mehr oder eher sporadisch weiterentwickelt zu werden.",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>IoT Monitoring</span>"
    ]
  },
  {
    "objectID": "E07_MQTT.html#aufgabe-2-mqtt-mit-python-verwenden",
    "href": "E07_MQTT.html#aufgabe-2-mqtt-mit-python-verwenden",
    "title": "10  IoT Monitoring",
    "section": "Aufgabe 2: MQTT mit Python verwenden",
    "text": "Aufgabe 2: MQTT mit Python verwenden\nNun verwenden wir die Bibliothek paho-mqtt in Python um MQTT Messages zu senden oder empfangen. Folgende zwei Code Snippets zeigen wie ein Publisher und Subscriber in Python minimal implementiert werden können.\n\n\n\nDevice sendet Sensordaten und Topic an den MQTT Broker, ein weiteres Gerät abonniert (subscribe) dieses Topic und kann so die gesendeten Daten an das entsprechende Topic empfangen. In dieser Übung über ein Python Script für Publish und Subscribe\n\n\nScript 1: mqtt_sub.py - Subscriber\nimport paho.mqtt.client as mqtt \n1ip = \"127.0.0.1\"\n2topic = \"iot/temperature\"\n\n# Callback Funktion für den Verbindungsaufbau\n3def on_connect(client, userdata, flags, rc):\n    print(\"Connected - code: \"+str(rc)) \n4    client.subscribe(topic)\n  \n# Callback Funktion für eingehende Nachrichten\n5def on_message(client, userdata, msg):\n    print(msg.topic+\" \"+str(msg.payload))\n  \n# Erstellen des MQTT Clients\n6client = mqtt.Client()\nclient.on_connect = on_connect\nclient.on_message = on_message\n7client.connect(ip, 1883, 60)\nclient.loop_forever()\n\n1\n\nIP Adresse des MQTT Brokers\n\n2\n\nTopic auf welches der Subscriber hört\n\n3\n\nCallback Funktion on_connect wird ausgeführt, wenn die Verbidnung steht\n\n4\n\nSubscription für das Topic\n\n5\n\nCallback Funktion on_publish wird ausgeführt, wenn eine Nachricht empfangen (publish) wird\n\n6\n\nErstellen eines MQTT Clients und Zuweisung der Callback Funktionen\n\n7\n\nVerbindung zum MQTT Broker herstellen und auf eingehende Nachrichten warten (loop_forever)\n\n\nScript 2: mqtt_pub.py - Publisher\nimport paho.mqtt.publish as publish \n1ip = \"127.0.0.1\"\ntopic = \"iot/temperature\"\n2publish.single(topic, \"22.0\", hostname=ip, port=1883)\n\n1\n\nIP Adresse des MQTT Brokers und Topic definieren\n\n2\n\nNachricht mit Topic an den MQTT Broker (ip,port) senden\n\n\n\nÜbung 10.2  \n\nSpeichere die beiden Dateien mqtt_pub.py und mqtt_sub.py im Ordner mqtt ab.\n(Optional: Passe die IP Adresse des MQTT Brokers an, falls ein anderer MQTT Broker genutzt werden soll.)\nÖffne zwei Terminals und führe diese mit python mqtt_pub.py und python mqtt_sub.py aus.\n\n\nFalls die Library paho-mqtt nicht installiert ist, kann diese in der aktivierten virtuellen Environment source ~/.env/bin/activate mit pip install paho-mqtt.",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>IoT Monitoring</span>"
    ]
  },
  {
    "objectID": "E07_MQTT.html#aufgabe-3-sensordaten-mit-mqtt-übertragen",
    "href": "E07_MQTT.html#aufgabe-3-sensordaten-mit-mqtt-übertragen",
    "title": "10  IoT Monitoring",
    "section": "Aufgabe 3: Sensordaten mit MQTT übertragen",
    "text": "Aufgabe 3: Sensordaten mit MQTT übertragen\nPasse nun das Script mqtt_pub.py an, so dass die Temperatur vom Sensor BME688 ausgelesen und über MQTT übertragen wird. Die Temperatur soll alle 10 Sekunden übertragen werden. Nutze hierfür das Script zum Auslesen der Sensordaten aus der Übung E01 Luftqualität und passe dieses an.\n\nÜbung 10.3  \n\nSpeichere das mqtt_pub.py als mqtt_pub_bme688.py im Ordner mqtt ab.\nErgänze das Script um die Funktionen zum auslesen der Temperatur des BME688 Sensors.\nErgänze das Script für das Auslesen der Luftfeuchtigkeit und Luftdruck und ergänze die topics mit iot/humidity und iot/pressure.\nErweitere das Script mqtt_sub.py um die Subscription für die Topics iot/humidity und iot/pressure und speichere es als mqtt_sub_bme688.py ab.\nÖffne zwei Terminals und führe diese mit python mqtt_pub_bme688.py und python mqtt_sub_bme688.py aus.",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>IoT Monitoring</span>"
    ]
  },
  {
    "objectID": "E07_MQTT.html#aufgabe-4-mqtt-mit-node-red-verwenden",
    "href": "E07_MQTT.html#aufgabe-4-mqtt-mit-node-red-verwenden",
    "title": "10  IoT Monitoring",
    "section": "Aufgabe 4: MQTT mit Node-RED verwenden",
    "text": "Aufgabe 4: MQTT mit Node-RED verwenden\nNode-Red ist ein grafisches Entwicklungswerkzeug für IoT, ein low-code Tool für event-driven applications. Es bietet eine browserbasierte und datenstromorientierte “Flow” Programmierung für die Verarbeitung von Sensordaten (ähnlich wie FME oder graphische Modellierungswerkzeuge in GIS). Die Implementation von Node-Red ist in JavaScript und basiert auf node.js. Datenverarbeitungsflows können gespeichert und wiederverwendet werden. Im Arbeitsbereich (Abb. 10.2) können sogenannte Nodes, die unterschiedliche Funktionen erfüllen, zu einem Daten-“Flow” werden. Nodes können auch selbst erstellt werden. Es gibt eine Vielzahl von Nodes, die von der Community entwickelt wurden, die über den Node-Red Palette Manager installiert werden können. Core Nodes von Node-Red sind:\n\nInject Node: Kann einen Flow über den Button direkt auslösen oder in regelmässigen Abständen mit Zeitstempel oder vordefinierten Nachrichten (msg) senden.\nDebug Node: Kann die Nachrichten (msg) in Debug Sidebar anzeigen lassen.\nFunction Node: Kann mit JavaScript Funktionen den Inhalt der Nachrichten (msg) verändern.\nChange Node: Ermöglicht das Ändern von Eigenschaften einer Nachricht (ohne den Funktion Node zu nützen) um beispielsweise Eigenschaften zu setzen, ändern oder löschen.\nSwitch Node: Kann Nachrichten (msg) anhand von Regeln auswerten in verschiedene Ausgänge leiten (wie ein Switch Case in der Programmierung).\nTemplate Node: Kann über Eigenschaften einer Nachricht und einer Vorlage (Template) neue Nachricht nach Vorlage erstellen: Nachricht: {{payload}}! wird Nachricht: 1570439577309 !.\n\nNode-Red kann über den Browser auf dem Raspberry Pi oder via Laptop gestartet werden. Öffne den Browser und gebe die IP Adresse des Raspberry Pi mit dem Port 1880 ein: http://&lt;ip-adresse&gt;:1880. Führt nun das Kurztutorial zu Node-Red aus: Node-Red Getting Started: First Flow. In diesem Tutorial wird ein Flow erstellt, der eine Nachricht mit einem Zeitstempel ausgibt.\n\n\n\n\n\n\nAbb. 10.2: Node-Red Flow der Daten in das Topic iot/temperature published, und Nachrichten aus dem Topic iot/temperature subscribed.\n\n\n\n\nÜbung 10.4 Erstelle einen Flow der Nachrichten an den MQTT Broker senden und Nachrichten vom MQTT Broker empfangen kann.\n\nFüge hierfür einen Inject Node, einen Debug Node und einen MQTT Output Node hinzu. Öffne die Einstellungen des MQTT Output Nodes (siehe Abb. 10.3) und setze die IP Adresse des MQTT Brokers und das Topic auf iot/temperature. Starte den Flow und überprüfe, ob die Nachrichten an den MQTT Broker gesendet werden.\nErstelle nun einen weiteren Flow, der die Nachrichten vom MQTT Broker empfängt und in der Debug Sidebar anzeigt. Füge hierfür einen MQTT Input Node (siehe Abb. 10.3) und einen Debug Node hinzu. Öffne die Einstellungen des MQTT Input Nodes und setze die IP Adresse des MQTT Brokers und das Topic auf iot/temperature. Starte den Flow und überprüfe, ob die Nachrichten vom MQTT Broker empfangen werden.\nErgänze den Flow um einen MQTT Input Node für die Topics iot/humidity und iot/pressure und je einen Debug Node. Starte den Flow und überprüfe, ob die Nachrichten vom MQTT Broker empfangen werden.\n\n\n\n\n\n\n\n\nAbb. 10.3: Node-Red MQTT Node Einstellungen setzen, (1) Name angeben, (2) Server Einstellungen öffnen und (3) IP Adresse des MQTT Brokers setzen, (4) subscribe to single topic wählen und (5) Topic iot/temperature setzen.\n\n\n\n\nFlows stoppen: Um einen Flow in der Ausführung zu stoppen, kann dieser über den Tab Flow (rechte Maustaste) deaktiviert werden (disable flow) und mit einem erneuten Übernehmen (Deploy) wird der Flow gestoppt.",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>IoT Monitoring</span>"
    ]
  },
  {
    "objectID": "E07_MQTT.html#aufgabe-5-node-red-mqtt-mit-influxdb-verwenden",
    "href": "E07_MQTT.html#aufgabe-5-node-red-mqtt-mit-influxdb-verwenden",
    "title": "10  IoT Monitoring",
    "section": "Aufgabe 5: Node-Red MQTT mit InfluxDB verwenden",
    "text": "Aufgabe 5: Node-Red MQTT mit InfluxDB verwenden\nInfluxDB ist die Datenbank, die für die Erfassung, Speicherung, Verarbeitung und Visualisierung von Zeitreihendaten entwickelt wurde. Zeitreihendaten sind Datenpunkte, die in zeitlicher Sequenz erfasst wurden und bestehen in der Regele aus aufeinanderfolgenden Messungen aus derselben Quelle, wie beispielsweise die Temperaturdaten des BME688.\nInfluxDB organisiert die Zeitreihendaten in Buckets (anstatt Datenbanken) und Messungen (Measurements). Ein Bucket kann mehrere Messungen enthalten, wobei Messungen Felder und Tags enthalten können (influxdata, 2023). Eine Messung enthält Felder mit key-value Paaren von Messwerten, die sich über die Zeit ändern. Tags sind key-value Paare, die sich nicht über die Zeit ändern und für die Filterung und Gruppierung verwendet werden können.\nDas Tutorial Getting Started zeigt die ersten Schritte mit InfluxDB.\n\n\n\nIoT Datenfluss mit Node-Red MQTT und InfluxDB. Python Script publiziert (publish) die Sensormesswerte und das Topic an den MQTT Broker, NodeRed abonniert (subscribe) ein oder mehrere Topics und speichert die Sensormesswerte in einer InlfuxDB Datenbank.\n\n\nDie graphische Oberfläche von InfluxDB kann über den Browser auf dem Raspberry Pi oder via Laptop gestartet werden. Öffnet nun den Browser und gebe die IP Adresse des Raspberry Pi mit dem Port 8086 ein: http://&lt;ip-adresse&gt;:8086.\nErstellt über die linke Menuleiste unter Load Data einen neuen Bucket mit dem Namen iot, falls dieser nicht schon existiert. Kopiert unter load Data / API Tokens den Token für den Zugang zur Datenbank.\nDiese Angaben (bucket und API Token) werden für den InfluxDB Node in Node-Red benötigt. Die Einstellungen des InfluxDB Node benötigen die Angaben, wohin die Daten in der Datenbank gespeichert werden (links in Abb. 10.4) mit Angaben zum Bucket (Datenbankname), Organisation2 und measurement und die Serververbindung (rechts in Abb. 10.4) mit der IP Adresse und das Token für den Zugang zur Datenbank.\n\nFalls keine Nodes für InfluxDB in Node-Red vorhanden sind, kann die Erweiterung node-red-contrib-influxdb über das Hauptmenu Palette verwalten im Tab Installation installiert werden.\n\n\n\n\n\n\n\nAbb. 10.4: Einstellungen der InflxDB Nodes in Node-Red, links: Einstellungen zur Datenbank (1) mit Angaben zur Organisation (5), Bucket (6) und Namen der Messung measurement (7), rechts: Einstellungen zur Datenbankverbindung (2) mit der URL und Port der InfluxDB (3) und dem API Token (4), für den Zugang zur Datenbank.\n\n\n\nDie Messwerte können direkt in die InfluxDB geschrieben werden, jedoch fehlen da noch die Tags, die für die Filterung und Gruppierung verwendet werden können. Diese können über den Change Node hinzugefügt werden, wie in Abb. 10.5 gezeigt. Hierbei wird der Wert der Payload in ein Feld mit dem Namen temperature geschrieben und die Tags device und sensor werden hinzugefügt. Dieselbe Struktur kann alternativ auch mit dem Function Node erstellt werden, siehe Abb. 10.5 rechts. Hierbei wird der Wert der Payload in ein Feld mit dem Namen temperature geschrieben und die Tags device und sensor werden hinzugefügt. Die Bezeichnung der Messung temperature wird im InfluxDB Node definiert oder kann im Function Node überschrieben werden.\n\n\n\n\n\n\nAbb. 10.5: Über den Change Node, wie auch den Function Node kann mit JavaScript der Inhalt der Payload verändert werden und diesen für den Import in die InfluxDB angepasst werden.\n\n\n\nmsg.payload = [{ \n1    temperature:msg.payload\n2}, { device:\"RPI_01\", sensor:\"BME688\" }];\n3msg.measurement=\"temperature\";\nreturn msg;\n\n1\n\nWerte der Payload in Payloadstruktur für die InfluxDB schreiben\n\n2\n\nTags der Messung zuweisen\n\n3\n\nOptional measurement kann im InfluxDB Node oder im Funktionsknoten definiert werden\n\n\nInfluxDB bietet über das Menu Data Explorer eine einfache Möglichkeit die Daten zu visualisieren. Der Query Builder (Abb. 10.6) hilft bei der Erstellung von Abfragen mit der über die Fields und Tags gefiltert werden kann, die dann über den Button Submit ausgeführt und dargestellt werden können. Die erstellte Query kann über den Script Editor (Abb. 10.6) angezeigt werden.\n\n\n\n\n\n\nAbb. 10.6: Über den Data Explorer können in InfluxDB einfach Abfragen zusammengestellt und über submit visualisiert werden\n\n\n\n\nÜbung 10.5  \n\nErstellt nun einen Flow der die Nachrichten des Topics iot/temperature vom MQTT Broker empfängt und in die InfluxDB schreibt.\nErstellt erst einen flow der nur die Nachrichten ohne Tags in die InfluxDB schreibt\nErgänzt den Flow mit einem Change oder Function Node um die Tags device und sensor hinzuzufügen.\nVisualisiert den Temperaturverlauf des BME688 in der InfluxDB mit dem Data Explorer und studiert die Flux Abfragesprache.\nErstellt einen Flow der die Nachrichten der Topics iot/humidity und iot/pressure vom MQTT Broker empfängt und in die InfluxDB schreibt.\n(Optional) erstellt im Menu Dashboard eine Visualisierung der Messwerte.",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>IoT Monitoring</span>"
    ]
  },
  {
    "objectID": "E07_MQTT.html#aufgabe-6-influxdb-mit-grafana-verwenden",
    "href": "E07_MQTT.html#aufgabe-6-influxdb-mit-grafana-verwenden",
    "title": "10  IoT Monitoring",
    "section": "Aufgabe 6: InfluxDB mit Grafana verwenden",
    "text": "Aufgabe 6: InfluxDB mit Grafana verwenden\nGrafana ist eine Open-Source Anwendung für die grafische Darstellung von Daten aus den verschiedenen Datenquellen, wie Postgres, SQLite oder InfluxDB. Über Grafana können interaktive Dashboards mit vielen Visualisierungsansätzen erstellt werden. In dieser Übung wird Grafana mit der InfluxDB Datenbank verwendet.\n\nMonitoring der Lichtverschmutzung am Nachthimmel TESS (Telescope Encoder and Sky Sensor) ist ein Photometer (Zamorano et al., 2016) für das Stars4All Citizen Science Projekt mit dem Ziel die Lichtverschmutzung weltweit in der Nacht zu vermessen, welche nicht nur für die Umwelt problematisch ist, sondern auch für astronomische Beobachtungen. Die TESS Geräte senden von verschiedenen Standorten weltweit ihre Messungen welche über der folgende Dashboard mit Grafana der Öffentlichkeit zur Verfügung gestellt werden. Dashboard: https://tess.dashboards.stars4all.eu/, Messungen der Lichtverschmutzung am Beispiel des Naturparks Gantrisch in der Schweiz. https://tess.dashboards.stars4all.eu/d/datasheet_stars926/stars926?orgId=1\n\n\n\nGrafana Dashboard der Messdaten des TESS Photometes im Naturpark Gantrisch dem ersten Dark Sky Park der Schweiz\n\n\n\nÖffnet nun den Browser und gebt die IP Adresse des Raspberry Pi mit dem Port 3000 ein: http://&lt;ip-adresse&gt;:3000. Unter Connections / Data Sources können Grafana Datenquellen hinzugefügt werden, wählt nun InfluxDB um Grafana mit der InfluxDB zu verbinden. Setzt folgende Einstellungen (Abb. 10.7) und speichert diese:\n\nQuery Language: Wählt in den Einstellungen zu Query Language die Abfragesprache Flux.\nHTTP: Setzt die IP Adresse des Raspberry Pi und den Port 8086: http://localhost:8086.\nAuth: aktiviert Basic Auth\nBasic Auth Details: Setzt den InfluxDB Benutzer und das Passwort für die InfluxDB\nInfluxDB Details: Setzt die InfluxDB Organisation fhnw, den API Token, und den InfluxDB Bucket iot.\n\n\n\n\n\n\n\nAbb. 10.7: InfluxDB als Datenquelle in Grafana hinzufügen mit den entsprechenden Angaben.\n\n\n\nIst die Verbindung erstellt, können neue Dashboards erstellt werden. Die Queries, die für die Visualisierung verwendet werden sollen, können über den Query Builder in InfluxDB erstellt und in Grafana beim Erstellen der Panels (Abb. 10.8) reinkopiert werden.\n\n\n\n\n\n\nAbb. 10.8: Flux Queries der Datenabfragen im Data Explorer können in Grafana für die Visualisierung kopiert und genutzt werden.\n\n\n\n\nÜbung 10.6  \n\nErstellt eine Verbindung zwischen Grafana und der InfluxDB.\nErstellt ein Dashboard mit einer Visualisierung der Temperatur, Luftfeuchtigkeit und Luftdruck des BME688 Sensors.",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>IoT Monitoring</span>"
    ]
  },
  {
    "objectID": "E07_MQTT.html#aufgabe-7-influxdb-mit-python-verwenden-optional",
    "href": "E07_MQTT.html#aufgabe-7-influxdb-mit-python-verwenden-optional",
    "title": "10  IoT Monitoring",
    "section": "Aufgabe 7: InfluxDB mit Python verwenden (optional)",
    "text": "Aufgabe 7: InfluxDB mit Python verwenden (optional)\nAnstatt mit Node-Red können die Daten des Sensors direkt in die InfluxDB geschrieben werden. Folgender Code zeigt wie die Daten des BME688 Sensors mit Python ausgelesen und in die InfluxDB geschrieben werden können. Teste erst, ob der influxdb-client installiert ist und installiere diesen falls nicht mit dem Befehl pip3 install influxdb-client. Folgendes Tutorial zeigt wie die Daten mit Python in die InfluxDB geschrieben werden können: Getting Started with Python and InfluxDB v2.0.\n\n\n\nDirektes Speichern der Sensormessdaten in der Influxdb ohne MQTT Protokoll. Hierbei gilt zu beachten, dass beide Geräte eine aktive Verbindung haben.\n\n\nfrom datetime import datetime\nimport time\n\nfrom influxdb_client import InfluxDBClient, Point, WritePrecision\nfrom influxdb_client.client.write_api import SYNCHRONOUS\n\n# Generieren ein Token in der InfluxDB UI unter dem Tab \"Data / Tokens Tab\"\ntoken = \"&lt;influxdb-token&gt;\"\norg = \"fhnw\"\nbucket = \"iot\"\n\nclient = InfluxDBClient(url=\"http://localhost:8086\", token= token, org= org)\nwrite_api = client.write_api(write_options = SYNCHRONOUS)\n\ntemperature = 22.0\ndata = Point(\"measures\").tag(\"fields\", 2).field(\"temperature\", temperature)\nwrite_api.write(bucket = bucket, record = data)\n\nÜbung 10.7 Schreibe nun mit Hilfe des Tutorials und dem Beispielcode ein Python Script, welches die Temperatur, Luftfeuchtigkeit und Luftdruck des BME688 Sensors ausliest und in die InfluxDB schreibt.\n\n\n\n\n\ninfluxdata. (2023). Get Started with InfluxDB  InfluxDB OSS v2 Documentation. https://docs.influxdata.com/influxdb/v2/get-started/.\n\n\nZamorano, J., García, C., Tapia, C., Miguel, A. S. de, Pascual, S., & Gallego, J. (2016). STARS4ALL Night Sky Brightness Photometer. International Journal of Sustainable Lighting, 18, 49–54. https://doi.org/10.26607/ijsl.v18i0.21",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>IoT Monitoring</span>"
    ]
  },
  {
    "objectID": "E07_MQTT.html#footnotes",
    "href": "E07_MQTT.html#footnotes",
    "title": "10  IoT Monitoring",
    "section": "",
    "text": "Topics, die mit $ beginnen sind reserviert für interne Informationen des Brokers und Clientstatistiken, oft in der Form $SYS/. Beispielsweise zeigt $SYS/broker/clients/connected die Anzahl der verbundenen Clients. Mit dem Wildcard # Filter könnt Ihr mit $SYS/# alle Systeminformationen der Brokers anzeigen lassen.↩︎\nwird bei der Erstellung der Datenbank definiert↩︎",
    "crumbs": [
      "Praktika",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>IoT Monitoring</span>"
    ]
  },
  {
    "objectID": "A1_Rasperry_Pi.html",
    "href": "A1_Rasperry_Pi.html",
    "title": "Anhang A — Raspberry Pi",
    "section": "",
    "text": "Raspberry Pi Image schreiben\nDer Raspberry Pi führt keinen internen Speicher mit sich, sondern benötigt eine SD-Karte. Auf dieser SD-Karte wird das Betriebssystem installiert, respektive als Image auf die MicroSD Karte geschrieben. Die SD-Karte muss mindestens 8 GB Speicherplatz haben idealerweise 16 GB oder mehr.\nSoftware: Raspberry Pi - Software\nTutorial: Raspberry Pi - How to set up Raspberry Pi\nRaspberry Pi Imager ist die von Raspberry Pi erstellte Software für das Schreiben von Images auf eine SD Karte. Der Imager stellt direkt auch weitere Images wie Ubuntu, Medienzentren, 3D Druck etc. zur Verfügung. Alternative Image Burner sind Balena Etcher und Win32DiskImager.\nDas Betriebssystem Raspberry Pi OS ist ein auf Debian basiertes Betriebssystem mit Anpassungen für die Hardware auf dem Raspberry Pi. Es gibt eine Lite Version ohne Desktop und eine Desktop Version mit Desktop. Die Desktop Version ist für den Einstieg empfehlenswert, da sie die grafische Oberfläche bietet und die Konsole. Die Lite Version ist für den produktiven Einsatz empfehlenswert, da sie weniger Ressourcen benötigt und somit mehr Ressourcen für die Anwendungen zur Verfügung stehen. Dazu muss der Raspberry Pi über das Netzwerk erreichbar sein, beispielsweise über SSH.\nImage schreiben mit Raspberry Pi 64-bit (Desktop Version) und mit den erweiterten Optionen Voreinstellungen zu SSH (Ja), WiFi (Heimnetzwerk), Konto und unter Sprache die Zeitzone Europe/Zurich und das das Tastaturlayout CH setzen.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Raspberry Pi</span>"
    ]
  },
  {
    "objectID": "A1_Rasperry_Pi.html#raspberry-pi-image-schreiben",
    "href": "A1_Rasperry_Pi.html#raspberry-pi-image-schreiben",
    "title": "Anhang A — Raspberry Pi",
    "section": "",
    "text": "Für die Nutzung am Campus nutzen wir die Desktop Version, da wir die grafische Oberfläche für das aktivieren des Internetzugangs benötigen.\n\n\n\nDie Einstellungen können später in der Konsole mit dem Programm raspi-config geändert werden.\n\n\n\n\nRasperry Pi Imager ausführen mit (1) Betriebssystem wählen, (2) Raspberry Pi OS (Other), (3) Raspberry Pi OS 64-bit, (4) erweiterte Einstellungen wählen und unter diesen Voreinstellungen zum Konto, SSH, Zeitzone und Tastaturlayout vordefinieren.\n\n\n\nFür Testzwecke kann es sinnvoll sein den Standardkontonamen pi und das Standardpasswort raspberry zu verwenden. Jedoch sollte der Kontonamen und das Passwort für den produktiven Einsatz geändert werden, vor allem wenn der Raspberry Pi mit dem Internet verbunden ist, beispielsweise mit einem aktivierten SSH Zugang.\n\n\nRaspberry Pi Image auf SD-Karte schreiben\n\nInstalliere den Raspberry Pi Imager\nSchreibe Raspberry Pi OS 64-bit auf die SD Karte\nAktiviere SSH und setze die Spracheinstellungen (WiFi Name und Password des Netzwerks von Zuhause oder dem Mobile Hotspot)\nSD Karte in den Raspberry einsetzen\nMaus, Tastatur und Monitor anschliessen und dann mit dem Netzteil mit Strom versehen",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Raspberry Pi</span>"
    ]
  },
  {
    "objectID": "A1_Rasperry_Pi.html#raspberry-pi-einrichten",
    "href": "A1_Rasperry_Pi.html#raspberry-pi-einrichten",
    "title": "Anhang A — Raspberry Pi",
    "section": "Raspberry Pi einrichten",
    "text": "Raspberry Pi einrichten\nFür das Einrichten des Raspberry Pi wird die SD-Karte mit dem Image in den Raspberry Pi eingesetzt. Für das erstmalige Einrichten des Raspberry Pi OS ist ein Bildschirm, eine Tastatur und eine Maus erforderlich. Verbunden wird der Raspberry Pi über die HDMI-Schnittstelle mit dem Bildschirm und über die USB Schnittstelle mit der Tastatur und der Maus, dann wird die Stromversorgung über USB-C angeschlossen.\n\nGehäuse öffnen und SD Karten Slot öffnen\nDen Deckel durch leichtes Drücken mit zwei Finger bei (1) horizontal leicht in Pfeilrichtung drücken, nach einem Klick lässt sich das Gehäuse aufschieben. Der SD Karten-Slot lässt sich mit einem Stift in der Einbuchtung (3) mit leichtem Druck in Pfeilrichtung öffnen (4). Das Raspberry Pi Board kann durch ein leichtes Klicken in Pfeilrichtung (5) aus dem Gehäuse entfernt werden.\n\n\n\nGehäuse öffnen, SD Karte wechesln und das Board aus dem Gehäuse entfernen.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Raspberry Pi</span>"
    ]
  },
  {
    "objectID": "A1_Rasperry_Pi.html#wifi-verbindung-einrichten",
    "href": "A1_Rasperry_Pi.html#wifi-verbindung-einrichten",
    "title": "Anhang A — Raspberry Pi",
    "section": "WiFi Verbindung einrichten",
    "text": "WiFi Verbindung einrichten\nDas WiFi Network kann auch über den Desktop eingerichtet werden. Das WiFi Symbol in der oberen rechten Ecke des Desktops zeigt die verfügbaren WiFi Netzwerke an. Je nach Einstellungen muss hierbei noch das WiFi Land CH ausgewählt werden. Die WiFi Einstellungen können auch über die Konsole mit dem Programm raspi-config vorgenommen werden.\n\nFür die Verbindung mit dem Internet am Campus muss das Netzwerk fhnw-public ausgewählt werden. Im Browser kann über die Website https://mpp.ict.fhnw.ch mit dem FHNW Login oder über das Mobiltelefon die Verbindung hergestellt werden.\n\n\n\n\nWiFi Verbindung über den Desktop auf dem Campus herstellen. Das Netzwerk fhnw-public wählen und auf der Website https://mpp.ict.fhnw.ch die Verbindung mit dem FHNW Account oder via Mobile herstellen.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Raspberry Pi</span>"
    ]
  },
  {
    "objectID": "A1_Rasperry_Pi.html#ssh-verbindung-herstellen",
    "href": "A1_Rasperry_Pi.html#ssh-verbindung-herstellen",
    "title": "Anhang A — Raspberry Pi",
    "section": "SSH Verbindung herstellen",
    "text": "SSH Verbindung herstellen\n\n\n\n\n\n\nAbb. A.1: Shell über die Softwareleiste öffnen\n\n\n\nDas SSH Protokoll ermöglicht den direkten auf den Raspberry Pi über das Konsolenfenster. Hierfür wird die IP Adresse des Raspberry Pi benötigt. Die IP Adresse kann über das Programm ifconfig oder ip addr in der Konsole abgefragt werden.\n\n\n\nDie IP-Adresse für das Wi-Fi ist unter wlan0 bei inet aufgeführt. Falls der Raspberry Pi mit einem Ethernet Kabel mit dem Netzwerk verbunden ist, wird die IP Adresse unter eth0 bei inet aufgeführt.\n\n\nFür die Verbindung mit SSH zu Raspberry Pi existieren unterschiedliche Clients:\n\nDirekt über die Eingabeaufforderung in Windows mit ssh\nPuTTY https://putty.org (win) ein SSH und telnet client für Windows (auch portable Nutzung ohne Installation möglich)\nTabby https://tabby.sh (win, mac, linux) ein modernes open source Terminal für lokale Shell, Serielle Schnittstelle, SSH und Telnet Verbindungen, File Transfer mit SFTP und Konfigurationsmöglichkeiten (auch portable Nutzung ohne Installation möglich)\n\n\n\n\nSSH Verbindung mit Putty einrichten\n\n\n\nTabby\nNeues SSH Verbindungsprofil mit Tabby erstellen mit der IP Adresse des Raspberry Pi erstellen.\n\nUnter Einstellungen / Profile & Verbindungen ein Neues Profil anlegen\nIn der Auswahl SSH-Verbindung wählen\nUnter Host die IP Adresse Benutzername des Raspberry Pi setzen und speichern\n\n\n\n\nSSH Verbindung mit Tabby einrichten (1-5) und anwenden (6).\n\n\n\n\nDatentransfer mit SFTP\nRemote Datentransfer mit SFTP dem SSH File Transfer Protokoll ermöglicht ein einfaches Verwalten und auch sichern der Daten. Hierbei eignet sich die Software FileZilla oder WinSCP für den Datentransfer.\nIn Fillezilla eine SFTP Verbindung über Datei/Servermanager herstellen mit Server: &lt;IP Adresse Raspberry Pi&gt;, Protokoll: SFTP, und bei der Verbindungart normal wählen und dort Benutzername und Passwort des Raspberry Pi Users angeben.\n\n\n\nDatentransfer mit FileZilla. Eine neue Verbindung im Servermanager (1) erstellen unter Server die IP-Adresse des Raspberry Pi setzen mit dem SFTP Prokoll, und bei der Verbindungsart normal wählen und Benutzername und Passwort des Raspberry Pi angeben und mit “Verbinden” (4) die SFTP Verbindung aufbauen und im Hauptfenster (5) Daten transferieren.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Raspberry Pi</span>"
    ]
  },
  {
    "objectID": "A1_Rasperry_Pi.html#mobilen-hotspot-nutzen",
    "href": "A1_Rasperry_Pi.html#mobilen-hotspot-nutzen",
    "title": "Anhang A — Raspberry Pi",
    "section": "Mobilen Hotspot nutzen",
    "text": "Mobilen Hotspot nutzen\nAuf Windows kann ein mobiler Hotspot eingerichtet werden, um den Raspberry Pi mit dem Internet zu verbinden. Hierfür wird die Internetverbindung des Computers über das WLAN mit dem Raspberry Pi geteilt. Einen Mobilen Hotspot auf Windows einrichten, den Raspberry Pi mit dem Netzwerk verbinden und die IP Adressen der verbundenen Raspberry Pi’s werden im Reiter Mobiler Hotspot aufgeführt.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Raspberry Pi</span>"
    ]
  },
  {
    "objectID": "A1_Rasperry_Pi.html#raspberry-pi-config",
    "href": "A1_Rasperry_Pi.html#raspberry-pi-config",
    "title": "Anhang A — Raspberry Pi",
    "section": "Raspberry Pi Config",
    "text": "Raspberry Pi Config\nDie Grundlegenden Einstellungen des Raspberry Pi können mit dem Programm raspi-config vorgenommen werden, entweder über die Konsole oder über den Desktop. Beispielsweise kann dort SSH aktiviert werden, das Tastaturlayout geändert werden oder die Zeitzone angepasst werden. Oder weitere Schnittstellen wie I2C, SPI oder UART aktiviert werden.\n\n\n\nÜber die Konsole raspi-config starten und über das Konsolenmenu die Einstellungen anpassen. Im Beispiel wird über das Interface Options Menu SSH aktiviert.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Raspberry Pi</span>"
    ]
  },
  {
    "objectID": "A1_Rasperry_Pi.html#raspberry-pi-aktualisieren",
    "href": "A1_Rasperry_Pi.html#raspberry-pi-aktualisieren",
    "title": "Anhang A — Raspberry Pi",
    "section": "Raspberry Pi aktualisieren",
    "text": "Raspberry Pi aktualisieren\nGenerell empfiehlt es sich den Raspberry Pi aktuell zu halten und vor jeder Installation von Softwarepaketen folgende Befehle durchzuführen\nsudo apt update\nsudo apt upgrade\nsudo apt-get clean",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Raspberry Pi</span>"
    ]
  },
  {
    "objectID": "A1_Rasperry_Pi.html#raspberry-pi-im-netzwerk-auffinden",
    "href": "A1_Rasperry_Pi.html#raspberry-pi-im-netzwerk-auffinden",
    "title": "Anhang A — Raspberry Pi",
    "section": "Raspberry Pi im Netzwerk auffinden",
    "text": "Raspberry Pi im Netzwerk auffinden\nSobald der Raspberry Pi und auch andere Geräte mit dem Netzwerk verbunden sind kann deren IP Adresse mit Scanner Tools wie Angry IP Scanner, arp -a[^ arp -a listet die IP- und die MAC Adressen der einzelnen Geräte. Es kann ohne das Aufführen von Hostnamen jedoch aufwendig werden, die einzelnen Einträge durchzugehen um zu eruieren. Tipp: arp -a vor dem Booten des Raspberry Pi ausführen und ein zweites mal nachdem der Raspberry Pi vollständig gebootet hat nochmals und eruieren welche IP Adresse hinzugekommen ist.] oder nmap gefunden werden. Für Android und iOS existieren diverse Scanner Apps wie Fing oder Net Analyzer.\nDienste, die dass Netzwerk durchleuchten wie der Angry IP Scanner sind in grösseren Netzwerken wie bei Firmen oder Universitäten aus Sicherheitsgründen blockiert. Für den Nutzen im lokalen Netzwerk zu Hause ist der Angry IP Scanner jedoch ein nützliches Tool.\n\n\n\nBeispiel Scan eines lokalen Netzwerks mit dem Angry IP Scanner\n\n\n\n\n\n\nAriza, J. Á., & Baez, H. (2022). Understanding the Role of Single-Board Computers in Engineering and Computer Science Education: A Systematic Literature Review. Computer Applications in Engineering Education, 30(1), 304–329. https://doi.org/10.1002/cae.22439\n\n\nUpton, E. (2022). Supply Chain Update - It’s Good News! In Raspberry Pi.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Raspberry Pi</span>"
    ]
  },
  {
    "objectID": "A2_Sensorbox.html",
    "href": "A2_Sensorbox.html",
    "title": "Anhang B — Raspberry Pi Sensorbox",
    "section": "",
    "text": "Raspberry Pi 4 Set",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Raspberry Pi Sensorbox</span>"
    ]
  },
  {
    "objectID": "A2_Sensorbox.html#raspberry-pi-4-set",
    "href": "A2_Sensorbox.html#raspberry-pi-4-set",
    "title": "Anhang B — Raspberry Pi Sensorbox",
    "section": "",
    "text": "Inhalt des Raspberry Pi 4 Set, mit dem Brekaout Garden HAT, HDMI-HDMI Mini Kabel, Netzteil mit USB-C Anschluss und MicroSD Karte mit Adapter\n\n\n\nInhalt des Raspberry Pi 4 Set\n\n\nInhalt / Stückliste\n\n\n\n\n\nRaspberry Pi 4B - 4G\nRaspberry Pi\n\n\nPimoroni Breakout Garden HAT (I2C+SPI)\nPimoroni\n\n\nHighPi Pro Case for Raspberry Pi 4\nHiPi\n\n\nRaspberry Pi 15W USB-C Netzteil\nRaspberry Pi\n\n\nHDMI-HDMI Mini Kabel1\n\n\n\nMicroSD Karte mit SD Adapter - 32Gb\n\n\n\nHDMI-DVI Adapter",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Raspberry Pi Sensorbox</span>"
    ]
  },
  {
    "objectID": "A2_Sensorbox.html#sensorbox",
    "href": "A2_Sensorbox.html#sensorbox",
    "title": "Anhang B — Raspberry Pi Sensorbox",
    "section": "Sensorbox",
    "text": "Sensorbox\nFolgender Abschnitt gibt eine Übersicht der in diesem Kurs verwendeten Sensoren. Die Sensoren sind auf kleinen Platinen (Pimoroni-Breakouts) mit Randanschlüssen montiert und können einfach auf der Breakout Garden HAT Erweiterung auf den Raspberry Pi ohne löten und verkabeln montiert werden.\nDie Sensorbox enthält mehrere typische IoT Sensoren, die in vielen IoT Geräten Verwendung finden und im Geomatikkontext von Interesse sind.\n\nSensorbox Inhaltsübersicht\n\n\nSensor\nBeschreibung\nProdukt, Datenblatt, Library\n\n\n\n\nBME688\nTemperatur, Luftdruck, Luftfeuchtigkeit & Gas\nBME688 Breakout, Bosch BME688, bme680-python\n\n\nICM20948\n9DoF Motion Accelero-, Gyro-, Magnetometer\nICM20948 Breakout, ICM 20948, icm20948-python\n\n\nVL53L5CX\nTime of Flight ToF – 8x8 Multizone\nVL53L5CX Breakout, VL53L5CX, vl53l5cx-python\n\n\nAS7262\nSpektral Sensor 6 Kanäle: 450, 500,550, 570, 600, 650 nm\nAS7262 Breakout, AS7262, as7262-python\n\n\nMAX30101\nHerzfrequenz, Oximeter, Rauchsensor\nMAX30101 Breakout, MAX30101, max30105-python\n\n\nMLX90640\nThermal Kamera 32x24pixel Breakout – Wide angle (110°)\nMLX90640 Breakout, MLX90640, mlx90640-libraryAdafruit MLX90640\n\n\n\n1.54’’ LCD LCD Bildschirm SPI 240x240pixels\n1.54” SPI Colour Square LCD (240x240), st7789-python\n\n\n\nAdafruit I2C Hub Qwiic/Stemma QT 5 Port Hub\nI2C 5 Port Hub\n\n\n\n\n\n\nRaspberry Pi mit der Breakout Garden HAT Erweiterung (1) von Pimoroni und den Sensoren, (2) VL53L5CX Time of Flight, (3) BME688 Temperatur, Luftfeuchtigkeit und Gas, (4) ICM20948 9DoF Motion Accelero-, Gyro-, Magnetometer, (5) AS7262 Spektral Sensor, (6) MAX30101 Herzfrequenz, Oximeter, (7) MLX90640 Thermal Kamera, (8) 1.54” LCD Bildschirm Rauchsensor\n\n\n\nSensor Ausrichtung beachten\nBeim Anschliessen der Sensoren in die Schnittstellen des Breakout Garden unbedingt die korrekte Ausrichtung beachten! Die Beschriftung der Anschlüsse auf dem Sensor und dem Breakout Garden müssen übereinstimmen!\n\n\n\nSensor links korrekt angeschlossen, rechts falsch ausgerichtet angeschlossen.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Raspberry Pi Sensorbox</span>"
    ]
  },
  {
    "objectID": "A2_Sensorbox.html#footnotes",
    "href": "A2_Sensorbox.html#footnotes",
    "title": "Anhang B — Raspberry Pi Sensorbox",
    "section": "",
    "text": "HDMI Mini Anschluss schnell defekt↩︎",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Raspberry Pi Sensorbox</span>"
    ]
  },
  {
    "objectID": "A3_CheatSheet.html",
    "href": "A3_CheatSheet.html",
    "title": "Anhang C — Shell Cheat Sheet",
    "section": "",
    "text": "Einen unvollständige Übersicht gängiger Konsolen Befehle in Linux.\n\nRaspberry Pi runterfahren: sudo shutdown now\nRaspberry Pi neu starten: sudo reboot now\n\n\nNützliche Linux Befehle für die Kommandozeile (Shell)\n\n\n\n\n\n\nKommando\nKommentar\n\n\n\n\nsudo shutdown now\nSystem jetzt runterfahren / beenden\n\n\nsudo reboot now\nSystem jetzt neustarten\n\n\nman &lt;Befehl&gt;\nDokumentation / Manual von Paketen\n\n\n&lt;Befehl&gt; --help | less\nRuft die Optionen von Befehlen auf, die Option -less ermöglicht, dass mit den Cursortasten in den in längeren Hilfeseiten geblättert werden kann.\n\n\nwhoami\nUser Informationen anzeigen\n\n\npwd\nName des aktuellen Verzeichnisses aufzeigen\n\n\nls\nInhalt des aktuellen Verzeichnis zeigen\n\n\nls -l\nAuflisten aller Dateien und deren Details aktuellen Verzeichnis, wie Schreib- und Leseberechtigungen\n\n\nls  -a\nAlle Dateien inklusive der versteckten anzeigen\n\n\nls  -lh\nFilegrössen menschenfreundlich darstellen\n\n\nls  –lah\nAlle Dateien anzeigen\n\n\nfind\nSuche von Dateien mit sehr vielen Optionen für die Suche\n\n\ncd\nVerzeichnis wechseln (change directory) Beispiel: cd ../Documents wechsle in den übergeordneten Ordner mit “..” und gehe in das Verzeichnis “Documents”\n\n\nmkdir\nErstelle ein Verzeichnis mkdir Projekt\n\n\ncp\nKopiere eine Datei/Ordner cp &lt;quell-pfad&gt; &lt;ziel-pfad&gt;\n\n\nmv\nVerschieben/Umbenennen einer Datei/Ordner mv &lt;quell-pfad&gt; &lt;ziel-pfad&gt;\n\n\nrm\nDateien löschen\n\n\nrm -r\nOrdner und Inhalte löschen (alternativ rmdir), Option -f ohne Bestätigung\n\n\nchmod\nDatei- und Verzeichnisrechte ändern (r Lese-,w Schreib- und x Ausführrechte) für Nutzer und Nutzergruppen. Beispiel: chmod 777 Datei.txt gibt allen Nutzern Lese-, Schreib- und Ausführrechte.\n\n\nzip -r &lt;zip file name&gt; &lt;folder to zip&gt;\nDateien in einem Ordner in eine .zip Datei komprimieren. (Installationsbefehl, falls das Paket zip nicht installiert ist: sudo apt install zip unzip)\n\n\nunzip datei.zip\nZip-Datei entzippen\n\n\n\n\nNützliche Linux Befehle zur Softwareverwaltung und Installation\n\n\n\n\n\n\nKommando\nKommentar\n\n\n\n\nsudo &lt;Befehl&gt;\nEinmalig einen Befehl als su (super user =Administrator) ausführen (=super user do..) wie beispielsweise eine Installation von Paketen. Beim Ausführen wird das Passwort des su benötigt\n\n\nsudo apt install &lt;Paketname&gt;\nSoftware über die Software-Verwaltung APT (Advanced Package Tool) installieren\n\n\nsudo apt remove &lt;Paketname&gt;\nSoftware deinstallieren\n\n\nsudo apt purge &lt;Paketname&gt;\nKonfigurationsdateien nach der Deinstallation entfernen\n\n\nsudo apt autoremove\nAlle nicht mehr benötigten Pakete / Software\n\n\nsudo apt-cache showpkg &lt;Paketname&gt;\nZeigt alle Informationen über Pakete, Version, Abhängigkeiten und Installation an. apt-cache bietet mit sudo apt-cache dump eine Liste aller installierten Pakete, sudo apt-cache stats die Anzahl der installierten Pakete und deren Abhängigkeiten.\n\n\nsudo apt-cache search &lt;Paketname&gt;\nErmöglicht die Suche nach Paketen, beispielsweise sudo apt-cache search minesweep\n\n\nsudo apt update\nLaden der aktuellen Paketliste für das Betriebssystem\n\n\nsudo apt dist-upgrade\nAktualisieren des Betriebssystem (nach sudo apt-get update ausführen)\n\n\nsudo apt autoremove sudo apt autoclean\nEntfernt nicht mehr benötigte Dateien und Pakete\n\n\ndpkg --get-selections dpkg -l\nAlle Softwarepakete auflisten\n\n\ndpkg --get-selections | grep &lt;Paketname&gt;\nGewünschtes Softwarepaket mit grep filtern\n\n\nsudo dpkg -S &lt;Paketname&gt;\nInstallationsort von einem Softwarepaket anzeigen\n\n\ndpkg -l | grep &lt;Keyword&gt;\nNach einem installieren Softwarepaket suchen\n\n\ndpkg -s &lt;Paketname&gt; | grep Version\nVersion der installierten Software auflisten\n\n\nwhich &lt;Paketname&gt;\nPfad zu den installierten Binaries anzeigen\n\n\napt list &lt;Paketname&gt;\nVersion von einem Package anzeigen\n\n\napt list &lt;Paketname&gt; -a\nAlle verfügbaren Versionen von einer Software in diesem Repository auflisten\n\n\napt-cache policy &lt;Paketname&gt;\nMetadaten von einem Softwarepaket auflisten\n\n\napt-cache madison &lt;Paketname&gt;\nMetadaten von einem Softwarepaket auflisten\n\n\nsudo apt search &lt;Paketname&gt; sudo apt-cache search &lt;Paketname&gt;\nSuche, ob ein Softwarepaket verfügbar ist, ev zuerst die Paketliste mit sudo apt update aktualisieren.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Shell Cheat Sheet</span>"
    ]
  },
  {
    "objectID": "A4_Setup.html",
    "href": "A4_Setup.html",
    "title": "Anhang D — Raspberry Pi IoT Image",
    "section": "",
    "text": "Raspberry Pi Zugangsdaten\nNotiere die Zugangsdaten für den Raspberry Pi und die einzelnen Softwarekomponenten in der untenstehenden Tabelle. Die Zugangsdaten werden für die Übungen benötigt.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Raspberry Pi IoT Image</span>"
    ]
  },
  {
    "objectID": "A4_Setup.html#raspberry-pi-zugangsdaten",
    "href": "A4_Setup.html#raspberry-pi-zugangsdaten",
    "title": "Anhang D — Raspberry Pi IoT Image",
    "section": "",
    "text": "Zugangsdaten zu den einzelnen Konten notieren, gerade bei Datenbanken geht dies leicht vergessen.\n\n\n\n\n\n\n\n\nKonto\nUser\nPasswort\nKommentar\n\n\n\n\nRaspberry Pi\n\n\n\n\n\ninfluxdb\n\n\norganisation:\n\n\ngrafana",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Raspberry Pi IoT Image</span>"
    ]
  },
  {
    "objectID": "A4_Setup.html#installation-shell-script",
    "href": "A4_Setup.html#installation-shell-script",
    "title": "Anhang D — Raspberry Pi IoT Image",
    "section": "Installation Shell Script",
    "text": "Installation Shell Script\nShell Script für die Installation der erforderlichen Bibliotheken Script install_iot_software.sh mit dem unten aufgeführten Code erstellen und dem Script die Rechte für die Ausführung setzen mit\nsudo chmod +x install_iot_software.sh\nScript mit folgendem sh install_iot_software.sh oder ./install_iot_software.sh Befehl ausführen:\n\nInfluxDB Version: Die Version der InfluxDB auf die neuste Version im Script anpassen.\n\nShell Script: install_iot_software.sh - Bash Script zu Installation der Software und Libraries für das fächerübergreifende Modul 5200 IoT Installation von:\n\nPython Libraries Beispielcode für die Pimoroni Sensoren\nKlonen der Libraries mit Beispielen in Documents/Libraries\nJupyter Notebook\nMQTT, Mosquitto Broker und Clients\nNode-Red\nInfluxDB\nGrafana\nVNC\n\n\nZeilenumbrüche EOL Zeilenunterbrüche von Textdateien unterscheiden sich zwischen Unix LF und Windows CRLF Systemen. Bash Script müssen auf Linux Systemen Unix Zeilenumbrüche (EOL) LF aufweisen. Dies ist vor allem dann wichtig, wenn das Script auf einem Windows System erstellt wird. Windows verwendet standardmässig CRLF Zeilenumbrüche. In Visual Studio Code können die EOL Zeichen mit Ctrl+Shift+P und Change End of Line Sequence auf LF umgestellt werden oder über die Statusleiste unten rechts bei CRLF. In Notepad++ kann dies über Edit/EOL Conversion/Unix (LF) umgestellt werden.\n\ninstall_iot_software.sh: Bash Installations-Script mit Unix Zeilenumbrüchen EOL\n#!/bin/bash\nCOL='\\033[0;32m' # Primary Color\nNC='\\033[0m' # No Color\necho \"${COL}Raspberry Pi Version${NC}\"\nhostnamectl\ncat /proc/cpuinfo | grep Model\n\necho \"${COL}Raspberry Pi aktualisieren${NC}\"\nsudo apt update\nsudo apt full-upgrade -y\nsudo apt autoremove -y\n\necho \"${COL}VNC Installation${NC}\"\nsudo apt-get install realvnc-vnc-server\nsudo apt-get install realvnc-vnc-viewer\n\necho \"${COL}i2c-tools Installation${NC}\"\nsudo apt install python3-smbus\nsudo apt install -y i2c-tools\n\necho \"${COL}Mosquitto Server, Clients und Python Libraries Installation${NC}\"\nsudo apt install mosquitto -y\nsudo apt install mosquitto-clients -y\nsudo systemctl enable mosquitto.service\nsudo systemctl restart mosquitto\n\necho \"${COL}Node-Red Installation${NC}\"\ncurl -sL https://raw.githubusercontent.com/node-red/linux-installers/master/deb/update-nodejs-and-nodered -o update-nodejs-and-nodered.sh\nchmod +x update-nodejs-and-nodered.sh\nbash update-nodejs-and-nodered.sh --confirm-root --confirm-pi --confirm-install --no-init\nrm update-nodejs-and-nodered.sh\nsudo systemctl enable nodered.service\nsudo systemctl start nodered.service\n\necho \"${COL}InfluxDB Installation${NC}\"\nwget https://dl.influxdata.com/influxdb/releases/influxdb2-2.7.1-arm64.deb\nsudo dpkg -i influxdb2-2.7.1-arm64.deb\nsudo service influxdb start\n\necho \"${COL}Grafana Installation${NC}\"\nsudo apt-get install -y apt-transport-https software-properties-common wget\nsudo mkdir -p /etc/apt/keyrings/\nwget -q -O - https://apt.grafana.com/gpg.key | gpg --dearmor | sudo tee /etc/apt/keyrings/grafana.gpg &gt; /dev/null\necho \"deb [signed-by=/etc/apt/keyrings/grafana.gpg] https://apt.grafana.com stable main\" | sudo tee -a /etc/apt/sources.list.d/grafana.list\nsudo apt-get update\nsudo apt-get install grafana -y\n\nsudo systemctl daemon-reload\nsudo systemctl start grafana-server\nsudo systemctl enable grafana-server.service\nsudo apt autoremove -y\n\necho \"${COL}Klonen der Pimoroni Python Bibliotheken${NC}\"\necho \"${COL}in Documents/Libraries${NC}\"\ncd Documents\nmkdir Libraries\ncd Libraries\ngit clone https://github.com/pimoroni/st7789-python\ngit clone https://github.com/pimoroni/bme680-python \ngit clone https://github.com/pimoroni/icm20948-python\ngit clone https://github.com/pimoroni/as7262-python\ngit clone https://github.com/pimoroni/max30105-python\ngit clone https://github.com/pimoroni/vl53l5cx-python\ngit clone https://github.com/pimoroni/mlx90640-library\ncd ../../\nZip Datei des Ordners Libraries erstellen für das Backup der Beispielcode der einzelnen Sensoren.\ncd ~/Documents/\nzip -r Libraries.zip Libraries\n\nInstallation der Python Libraries mit venv\nMit dem Upgrade auf Raspberry Pi Bookworm wird Python auf die Version 3.11 aktualisiert. Ab dieser Version können Python Libraries nicht mehr systemweit installiert werden. Python Virtual Environment sind nun erfordert, entweder pro Projekt oder pro Userkonto siehe http://rptl.io/venv für weitere Informationen.\nErstelle eine Python Virtual Environment .env im Homeordner ~/ mit folgenden Befehlen für den User iot und aktiviere die Virtual Environment mit source ~/.env/bin/activate und deaktiviere die Virtual Environment mit deactivate. Wenn die Virtual Environment projetbasiert im Projektordner erstellt wird reicht es den Pfad zum Projektordner anzugeben z.B. python -m venv ~/Development/Projekt1/env und die Virtual Environment wird im Projektordner erstellt.\npython -m venv ~/.env\nsource ~/.env/bin/activate\nRequirements.txt Datei erstellen mit den Python Libraries, die in der Virtual Environment installiert werden sollen. Die Datei kann mit nano requirements.txt erstellt und mit Ctrl+o und Ctrl+x gespeichert werden. Python Libraries in der Virtual Environment installieren mit pip install -r requirements.txt. Nutze für die Installation folgende requirements.txt Datei. Kontrolliere mit pip list ob die Libraries installiert wurden.\nrequirements.txt: Python Libraries für die Pimoroni Sensoren\nmatplotlib\nscipy\npigments\nnumpy\njupyter\nrpi.gpio\nspidev\npillow\nnumpy\nst7789\nbme680\nicm20948\nas7262\nmax30105\nvl53l5cx-ctypes\nRPI.GPIO\nadafruit-blinka",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Raspberry Pi IoT Image</span>"
    ]
  },
  {
    "objectID": "A4_Setup.html#konfigurationsdateien-editieren",
    "href": "A4_Setup.html#konfigurationsdateien-editieren",
    "title": "Anhang D — Raspberry Pi IoT Image",
    "section": "Konfigurationsdateien editieren",
    "text": "Konfigurationsdateien editieren\n\nRaspberry Pi Einstellungen für I2C, SPI, SSH, VNC anpassen\nInterface Options aktivieren In den Raspberry Pi Konfigurationseinstellungen mit sudo raspi-config die Interface Optionen I2C, SPI, SSH und ev VNC (Virtual Network Computing) oder RPi Connect aktivieren. VNC, RPi Connect Hollingworth (2024)1 werden nur benötigt, wenn der Raspberry Pi über Fernzugriff gesteuert werden soll.\n\n\n\nÜber die Konsole raspi-config starten und über das Konsolenmenu (links) die Einstellungen in den Interface Options (rechts) I2C, SPI, SSH und ev VNC aktivieren.\n\n\n\n\nBaud rate des I2C Protokolls anpassen\nBaud rate des I2C Protokolls mit sudo nano /boot/firmware/config.txt öffnen und folgende Zeile ergänzen. Mit Ctrl+o und Ctrl+x speichern (siehe Raspberry Pi Ltd, 2024b).\ndtparam=i2c_arm=on,i2c_arm_baudrate=400000\n\n\nMosquitto Server Konfiguration\nMosquitto Server Konfiguration anpassen mit sudo nano /etc/mosquitto/mosquitto.conf und am Ende der Datei folgendes einfügen (Eclipse Foundation, 2021).\nlistener 1883\nallow_anonymous true\nMosquitto Server neu starten mit sudo systemctl restart mosquitto\nNode-Red Einstellungen initialisieren mit sudo node-red admin init\n\nyes installation customise settings\nyes keep settings file at default location\nno setup user security\nyes enable project features\nselect manual workflow\nselect default theme\nyes allow function nodes to load external modules\n\nNode-RED Settings File initialisation\n=====================================\nThis tool will help you create a Node-RED settings file.\n✔ Settings file · /root/.node-red/settings.js\n\nUser Security\n=============\n✔ Do you want to setup user security? · No\n\nProjects\n========\nThe Projects feature allows you to version control your flow using a local git repository.\n\n✔ Do you want to enable the Projects feature? · Yes\n✔ What project workflow do you want to use? · manual - you must manually commit changes\n\nEditor settings\n===============\n✔ Select a theme for the editor. To use any theme other than \"default\", you will need to install @node-red-contrib-themes/theme-collection in your Node-RED user directory. · default\n✔ Select the text editor component to use in the Node-RED Editor · monaco (default)\n\nNode settings\n=============\n✔ Allow Function nodes to load external modules? (functionExternalModules) · Yes\n\nSettings file written to /root/.node-red/settings.js",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Raspberry Pi IoT Image</span>"
    ]
  },
  {
    "objectID": "A4_Setup.html#installationen-testen-und-initialisieren",
    "href": "A4_Setup.html#installationen-testen-und-initialisieren",
    "title": "Anhang D — Raspberry Pi IoT Image",
    "section": "Installationen testen und initialisieren",
    "text": "Installationen testen und initialisieren\n\nMosquitto Broker\nTesten ob der Mosquitto Broker und Clients lokal auf dem Raspberry Pi funktionieren. Erstelle einen Subscriber der für das Topic iot/temperature eine Subscription erstellt.\nmosquitto_sub -h 127.0.0.1 -v -t 'iot/temperature'\nÖffne ein zweite Shell und erstelle einen Publisher für dasselbe Topic\nmosquitto_pub -h 127.0.0.1 -t 'iot/temperature' -m 'Aussentemperatur: 22° Celsius'\n\n\nNode-Red\nNode-Red Server testen : &lt;IP-Adresse&gt;:1880 http://192.168.1.205:1880 Influxerweiterung Palette installieren: Hamburgermenu oben-rechts / Paletten verwalten und unter Palette / Installation die Palette node-red-contrib-influxdb installieren.\n\n\n\nInfluxDB\nInfluxDB Server testen: &lt;IP-Adresse&gt;:8086 http://192.168.1.205:8086 Den Initial User erstellen mit Username, Password, Organisation und einem Bucket Name, der ersten Datenbank. Im Anschluss mit Logout/Login den Zugang verifizieren.\n\n\nOperator API token speichern! Das Superuser Passwort wird nur einmal angezeigt. Das Operator API token kopieren und an einem sicheren Ort speichern! Nach dem Logout/Login ist das Passwort nicht mehr sichtbar.\n\n\n\nGrafana\nGrafana Server testen: &lt;IP-Adresse&gt;:3000 http://192.168.1.205:3000 Grafana startet mit dem Default Admin User: admin und Passwort: admin. Das Passwort ändern und im Anschluss mit Logout/Login den Zugang verifizieren.\n\n\n\nJupyter Notebook\nJupyter Notebook testen &lt;IP-Adresse&gt;:9999 http://192.168.1.205:9999\n# jupter notebook installation testen\njupyter-notebook --no-browser --ip=192.168.1.205 --port 9999 --notebook-dir ~/Documents\n\n\nVNC Testen\nVNC Viewer auf dem PC installieren. Real VNC Viewer (standalone .exe, d.h. es ist keine Installation erforderlich).\nHinweis: Beim Starten des VNC Viewers muss man sich nicht anmelden sondern nur die Option Verwenden Sie RealVNC Viewer ohne sich anzumelden wählen.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Raspberry Pi IoT Image</span>"
    ]
  },
  {
    "objectID": "A4_Setup.html#raspberry-pi-image-verkleinern",
    "href": "A4_Setup.html#raspberry-pi-image-verkleinern",
    "title": "Anhang D — Raspberry Pi IoT Image",
    "section": "Raspberry Pi Image verkleinern",
    "text": "Raspberry Pi Image verkleinern\nDas Raspberry Pi Image kann mit dem Tool PiShrink verkleinert werden. PiShrink kann auf dem Raspberry Pi oder auf einen anderen Linux System wie Ubuntu oder einer virtuellen Machine mit einem Linux installiert und genutzt werden.\n\nBackup Image auf den lokalen Rechner mit Win32DiskImager lesen und in eine Image Datei schreiben.\nVirtuelle Machine mit Linux Ubuntu/Debian mit gemeinsamen Ordner starten\nMit dem Script https://github.com/Drewsif/PiShrink das Image verkleinern\nSD Karte Formatieren mit SD Card Formatter\nImage auf SD Karte schreiben mit Win 32 Disk Imager oder Raspberry Pi Imager\nFür die Archivierung kann das Image mit 7zip zusätzlich komprimiert werden (Archive Format .xz und Kompressionsstufe Ultra)\n\nTutorial: How I Backup and Shrink My SD Card Images - Youtube\nBackup Image mit Win32DiskImager schreiben, mit der Funktion Lesen/Read und diese als Image Datei auf den lokalen Rechner speichern.\n\n\n\nBackup Image der SD Karte schreiben mit Win32DiskImager und der Funktion Lesen/Read\n\n\nVirtuelle Machine mit VM VirtualBox starten und in den Einstellungen der VM über Geräte/Gemeinsame Ordner einen gemeinsamen Ordner zwischen VM und dem lokalen Rechner einrichten.\n\n\n\nGemeinsamer Ordner in der VM VirtualBox einrichten\n\n\nDas Image sollte nun im File Explorer unter “+ Other Locations” als Ordner host eingebunden und sichtbar sein.\n\n\n\nGemeinsamer Ordner host auf der VM Virtualbox eingebunden\n\n\nÖffne nun ein Terminal damit das Script pishrink.sh installiert und ausgeführt werden kann.\nTipp: Falls das Terminal nicht öffnet mit Ctrl+Alt+F3 in das TTY Terminal wechseln.\nTipp: Falls der VM User noch keine Adminrechte hat (bei einer Neuinstallation von Ubuntu ist das root Passwort nocht nicht gesetzt), können diese nachträglich gesetzt werden mit sudo passwd. Bei der Passwortabfrage das aktuelle User Passwort eingeben und das neue Root Passwort zweimal eingeben. Anschliessend als Root User anmelden mit su -.2\nGitHub: https://github.com/Drewsif/PiShrink\n# install prerequisites\nsudo apt install parted xz-utils\n# download the pishrink script\nwget -O ./pishrink.sh https://raw.githubusercontent.com/Drewsif/PiShrink/master/pishrink.sh\n# make the script executable\nchmod +x ./pishrink.sh\n# run pishrink on the .img file\nsudo ./pishrink.sh -v /host/&lt;rpi-imagefile&gt;.img\n# Komprimiere die Image als .xz Archive (eher langsam)\nxz -z -9e /host/&lt;rpi-imagefile&gt;.img\n\n\n\nScreenshot des Terminals während der Ausführung von pishrink\n\n\nImage mit 7-Zip zusätzlich komprimieren File Kontextmenu 7-Zip/Add to Archive und als Archive Format .xz sowie den Compression Level 9-Ultra wählen.\n\n\n\n7-Zip Einstellungen für die zusätzliche Kompression des Images mit .xz.\n\n\nFalls die SD Karte schon früher für Raspberry Pi Images benutzt wurde und mehrerere Partionen aufweist, kann es helfen die Karte mit dem SD Card Formatter nochmals von Grund auf zu formatieren.\n\n\n\nScreenshot des SD Card Formatter\n\n\n\n\n\n\nEclipse Foundation. (2021). Authentication Methods. In Eclipse Mosquitto. https://mosquitto.org/documentation/authentication-methods/.\n\n\nHollingworth, G. (2024). Raspberry Pi Connect. In Raspberry Pi.\n\n\nRaspberry Pi Ltd. (2024a). Raspberry Pi Connect Beta - Access Your Raspberry Pi from Anywhere. In Raspberry Pi. https://www.raspberrypi.com/software/connect/.\n\n\nRaspberry Pi Ltd. (2024b). Raspberry Pi Documentation Config.Txt. In Raspberry Pi. https://www.raspberrypi.com/documentation/computers/config_txt.html.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Raspberry Pi IoT Image</span>"
    ]
  },
  {
    "objectID": "A4_Setup.html#footnotes",
    "href": "A4_Setup.html#footnotes",
    "title": "Anhang D — Raspberry Pi IoT Image",
    "section": "",
    "text": "RPI Connect erlaubt über einen Relay Server die Verbindung zu einem Raspberry Pi herzustellen über WebRTC wie Browser Clients für Zoom, Slack, Microsoft Teams. Der Relay Server wird nur für die Erstellung der Verbindung benötigt und wird von Raspberry Pi kostenlos betrieben. RPi Connect installieren mit sudo apt install rpi-connect und mit sudo reboot neu starten.↩︎\nEinem User Adminrechte zuweisen: sudo usermod -a -G sudo &lt;username&gt;, Kontoinformationen id &lt;username&gt; aufzeigen.↩︎",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Raspberry Pi IoT Image</span>"
    ]
  }
]